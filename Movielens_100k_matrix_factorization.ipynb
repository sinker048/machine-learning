{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GygvA6oGy3KJ"
   },
   "source": [
    "# **資料前處理**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kRpkibzv5qSi"
   },
   "source": [
    "**安裝套件**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SAL7XIxD2sRZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys   #reload()之前必須要引入模組\n",
    "from numpy import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FhC98VZF51zf"
   },
   "source": [
    "**載入資料**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "-CbAuNap2-Ms",
    "outputId": "fda4943f-91b2-4209-920d-df37b760abcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 4808k  100 4808k    0     0  10.0M      0 --:--:-- --:--:-- --:--:-- 10.0M\n",
      "Archive:  ml-100k.zip\n",
      "   creating: ml-100k/\n",
      "  inflating: ml-100k/allbut.pl       \n",
      "  inflating: ml-100k/mku.sh          \n",
      "  inflating: ml-100k/README          \n",
      "  inflating: ml-100k/u.data          \n",
      "  inflating: ml-100k/u.genre         \n",
      "  inflating: ml-100k/u.info          \n",
      "  inflating: ml-100k/u.item          \n",
      "  inflating: ml-100k/u.occupation    \n",
      "  inflating: ml-100k/u.user          \n",
      "  inflating: ml-100k/u1.base         \n",
      "  inflating: ml-100k/u1.test         \n",
      "  inflating: ml-100k/u2.base         \n",
      "  inflating: ml-100k/u2.test         \n",
      "  inflating: ml-100k/u3.base         \n",
      "  inflating: ml-100k/u3.test         \n",
      "  inflating: ml-100k/u4.base         \n",
      "  inflating: ml-100k/u4.test         \n",
      "  inflating: ml-100k/u5.base         \n",
      "  inflating: ml-100k/u5.test         \n",
      "  inflating: ml-100k/ua.base         \n",
      "  inflating: ml-100k/ua.test         \n",
      "  inflating: ml-100k/ub.base         \n",
      "  inflating: ml-100k/ub.test         \n"
     ]
    }
   ],
   "source": [
    "!curl -O http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!unzip ml-100k.zip\n",
    "!cd ml-100k/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILXDefz73FXD"
   },
   "outputs": [],
   "source": [
    "data_fields = ['user id','item id', 'rating', 'timestamp']\n",
    "user_fields = ['user id', 'age', 'gender', 'occupation', 'zip code']\n",
    "data_df=pd.read_table(\"ml-100k/u.data\",names=data_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "colab_type": "code",
    "id": "JmQ3a2rB3O0S",
    "outputId": "f4cf0e5f-123c-4211-a30f-d27098d739af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>...</th>\n",
       "      <th>1643</th>\n",
       "      <th>1644</th>\n",
       "      <th>1645</th>\n",
       "      <th>1646</th>\n",
       "      <th>1647</th>\n",
       "      <th>1648</th>\n",
       "      <th>1649</th>\n",
       "      <th>1650</th>\n",
       "      <th>1651</th>\n",
       "      <th>1652</th>\n",
       "      <th>1653</th>\n",
       "      <th>1654</th>\n",
       "      <th>1655</th>\n",
       "      <th>1656</th>\n",
       "      <th>1657</th>\n",
       "      <th>1658</th>\n",
       "      <th>1659</th>\n",
       "      <th>1660</th>\n",
       "      <th>1661</th>\n",
       "      <th>1662</th>\n",
       "      <th>1663</th>\n",
       "      <th>1664</th>\n",
       "      <th>1665</th>\n",
       "      <th>1666</th>\n",
       "      <th>1667</th>\n",
       "      <th>1668</th>\n",
       "      <th>1669</th>\n",
       "      <th>1670</th>\n",
       "      <th>1671</th>\n",
       "      <th>1672</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "      <th>1682</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows × 1682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item id  1     2     3     4     5     6     ...  1677  1678  1679  1680  1681  1682\n",
       "user id                                      ...                                    \n",
       "1         5.0   3.0   4.0   3.0   3.0   5.0  ...   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "2         4.0   NaN   NaN   NaN   NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "3         NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "4         NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "5         4.0   3.0   NaN   NaN   NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "...       ...   ...   ...   ...   ...   ...  ...   ...   ...   ...   ...   ...   ...\n",
       "939       NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "940       NaN   NaN   NaN   2.0   NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "941       5.0   NaN   NaN   NaN   NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "942       NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "943       NaN   5.0   NaN   NaN   NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "\n",
       "[943 rows x 1682 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util_df=pd.pivot_table(data=data_df,values='rating',index='user id',columns='item id')\n",
    "\n",
    "util_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OSYSXfPV6FKH"
   },
   "source": [
    "**將遺失值填補為0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "colab_type": "code",
    "id": "Y-H1S4Z33Ra6",
    "outputId": "edf413e4-bd9b-4395-e231-4f4985890643"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>...</th>\n",
       "      <th>1643</th>\n",
       "      <th>1644</th>\n",
       "      <th>1645</th>\n",
       "      <th>1646</th>\n",
       "      <th>1647</th>\n",
       "      <th>1648</th>\n",
       "      <th>1649</th>\n",
       "      <th>1650</th>\n",
       "      <th>1651</th>\n",
       "      <th>1652</th>\n",
       "      <th>1653</th>\n",
       "      <th>1654</th>\n",
       "      <th>1655</th>\n",
       "      <th>1656</th>\n",
       "      <th>1657</th>\n",
       "      <th>1658</th>\n",
       "      <th>1659</th>\n",
       "      <th>1660</th>\n",
       "      <th>1661</th>\n",
       "      <th>1662</th>\n",
       "      <th>1663</th>\n",
       "      <th>1664</th>\n",
       "      <th>1665</th>\n",
       "      <th>1666</th>\n",
       "      <th>1667</th>\n",
       "      <th>1668</th>\n",
       "      <th>1669</th>\n",
       "      <th>1670</th>\n",
       "      <th>1671</th>\n",
       "      <th>1672</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "      <th>1682</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows × 1682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item id  1     2     3     4     5     6     ...  1677  1678  1679  1680  1681  1682\n",
       "user id                                      ...                                    \n",
       "1         5.0   3.0   4.0   3.0   3.0   5.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "2         4.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "3         0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "4         0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "5         4.0   3.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "...       ...   ...   ...   ...   ...   ...  ...   ...   ...   ...   ...   ...   ...\n",
       "939       0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "940       0.0   0.0   0.0   2.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "941       5.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "942       0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "943       0.0   5.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "\n",
       "[943 rows x 1682 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie=util_df.fillna(0)\n",
    "movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "R5zeUP-J3ZNS",
    "outputId": "f62f46f8-ca4d-40de-8fa8-8bc9cf8c478b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data=movie.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J-AufOtroacj"
   },
   "source": [
    "# **Basic model**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HrClK3n3wltX"
   },
   "source": [
    "$ \\hat\\gamma_{ui} = q^T _i  p_u  $\n",
    "\n",
    "$min_{q^*,p^*}\\sum_{(u,i)\\in\\kappa }{(\\gamma_{ui}-q^T _i  p_u)^2} +\\lambda (||q_i||^2+||p_u||^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LyzzIT6g41i_"
   },
   "source": [
    "其中：\n",
    "\n",
    "$\\gamma$ : user-item rating  $\\quad q_i$ :  item possesses those factors $\\quad p_u$ :  interest the user has in items that are high on the corresponding factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hn2vPfmrondi"
   },
   "source": [
    "## **SGD**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wBCA90ye5ExO"
   },
   "source": [
    "$e_{ui}=\\gamma_{ui} - q^T _i  p_u $\n",
    "*   $q_i \\leftarrow q_i+\\gamma \\cdot (e_{ui}\\cdot p_u - \\lambda \\cdot q_i)$\n",
    "*   $p_u \\leftarrow p_u+\\gamma \\cdot (e_{ui}\\cdot q_i - \\lambda \\cdot p_u)$\n",
    "\n",
    "其中 $\\gamma$ : learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gShMsbVX6QEv"
   },
   "source": [
    "**寫偏微分的function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gZ2_07g-3f0h"
   },
   "outputs": [],
   "source": [
    "def partial_residual(w,b,i,data):\n",
    "  zero=np.zeros(data.shape)\n",
    "  zero[row[i]][column[i]]=1\n",
    "  partialresidual=zero*(data[row[i]][column[i]]-np.dot(w.T, b))\n",
    "  return partialresidual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-iodV3-43nPR"
   },
   "outputs": [],
   "source": [
    "def partial_error(w,b,i,lamb,data):\n",
    "  total=0\n",
    "  row,column=data.nonzero()\n",
    "  partialerror=data[row[i]][column[i]]-w[0][row[i]]*b[0][column[i]]\n",
    "  return partialerror"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kmAPxX9P7BED"
   },
   "source": [
    "**寫一階梯度的function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MvrcqxEC3qcB"
   },
   "outputs": [],
   "source": [
    "def partial_step_gradient1(w,b,data,i,learning_rate,lamb):\n",
    "    w_gradient=(partial_residual(w,b,i,data).dot(b.T).T-w*lamb)\n",
    "    b_gradient=(partial_residual(w,b,i,data).T.dot(w.T).T-b*lamb)\n",
    "    new_w=w+(w_gradient*learning_rate)\n",
    "    new_b=b+(b_gradient*learning_rate)\n",
    "    return [new_w,new_b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b4XEXxsU7RUd"
   },
   "source": [
    "**寫square error loss + regularization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AlHrq7Lm4PPp"
   },
   "outputs": [],
   "source": [
    "def error(w,b,lamb,data):\n",
    "    totalError=0\n",
    "    matric=w.T.dot(b)\n",
    "    for i in range(0,data.shape[0]):\n",
    "        for j in range(0,data.shape[1]):\n",
    "            if data[i][j]!=0:\n",
    "                totalError+=(data[i][j]-matric[i][j])**2\n",
    "    totalError+=lamb*(w.dot(w.T)+b.dot(b.T))\n",
    "    return totalError[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g1lty1i28FgE"
   },
   "source": [
    "**寫 RMSE function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9RbXV31Z4UuB"
   },
   "outputs": [],
   "source": [
    "def rmse(data, Q, P):\n",
    "    I = data != 0  # Indicator function which is zero for missing data\n",
    "    ME = I * (data - np.dot(Q.T, P))  # Errors between real and predicted ratings\n",
    "    MSE = ME**2  \n",
    "    return np.sqrt(np.sum(MSE)/np.sum(I))  # sum of squared errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P31_btxJ76oW"
   },
   "source": [
    "**寫SGD function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9-I9hBzv3vcZ"
   },
   "outputs": [],
   "source": [
    "def partial_gradient_descent_runner1(data,starting_w,starting_b,learning_rate,lamb,max_iterations):\n",
    "    b=starting_b\n",
    "    w=starting_w\n",
    "    lasterror = 0\n",
    "    row,column=data.nonzero()\n",
    "    zero=np.zeros(data.shape)\n",
    "    partial_root_mean_square_error=[]\n",
    "    for j in range(max_iterations):\n",
    "      for i in range(0,100000):\n",
    "        zero=np.zeros(data.shape)\n",
    "        w,b=partial_step_gradient1(w,b,data,i,learning_rate,lamb)\n",
    "      partial_root_mean_square_error.append(rmse(data, w, b))\n",
    "      print(\"The {}-th iteration rmse = {}\".format(j+1,rmse(data, w, b)))\n",
    "      print(\"------------------------------\")\n",
    "      if np.abs(error(w,b,lamb,data)-lasterror)>0.1:\n",
    "        lasterror=error(w,b,lamb,data)\n",
    "      else:\n",
    "        break\n",
    "    return partial_root_mean_square_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YqjVi1Ie8O78"
   },
   "source": [
    "**模擬 Matrix Factorization by SGD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3hWntMGR3z8h"
   },
   "outputs": [],
   "source": [
    "w=np.array([[0]*data.shape[0]])\n",
    "b=np.array([[0]*data.shape[1]])\n",
    "lamb=0.01\n",
    "learning_rate=0.0004\n",
    "max_iterations=1\n",
    "row,column=data.nonzero()\n",
    "## partial_root_mean_square=partial_gradient_descent_runner1(data,w,b,learning_rate,lamb,max_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QPmyuVrj17Vm"
   },
   "source": [
    "## **Min-batch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CrNKDE2W2Qfs"
   },
   "outputs": [],
   "source": [
    "def minbatch_partial_residual(w,b,i,minbatch,data):\n",
    "  random.seed(10)\n",
    "  group_index=[[row[l],column[l]] for l in range(len(row))]\n",
    "  v=0\n",
    "  group=[]\n",
    "  while v < row.shape[0]:\n",
    "    group.append(group_index[v:v+minbatch])\n",
    "    v+=minbatch\n",
    "  group=np.array(group)\n",
    "  ##group[k][l][m]=> k-th group l-th data m=0 =>row m=1 =>column\n",
    "\n",
    "  zero=np.zeros(data.shape)\n",
    "  data_zero=np.zeros(data.shape)\n",
    "  for k in range(group[i].shape[0]):\n",
    "    zero[group[i][k][0]][group[i][k][1]]=1\n",
    "    data_zero[group[i][k][0]][group[i][k][1]]=data[group[i][k][0]][group[i][k][1]]\n",
    "  minbatch_partialresidual=zero*(data_zero-np.dot(w.T, b))\n",
    "  return minbatch_partialresidual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "obgWjxz44hiS"
   },
   "outputs": [],
   "source": [
    "def minbatch_partial_step_gradient1(w,b,data,i,learning_rate,lamb):\n",
    "    w_gradient=(minbatch_partial_residual(w,b,i,minbatch,data).dot(b.T).T-w*lamb)\n",
    "    b_gradient=(minbatch_partial_residual(w,b,i,minbatch,data).T.dot(w.T).T-b*lamb)\n",
    "    new_w=w+(w_gradient*learning_rate)\n",
    "    new_b=b+(b_gradient*learning_rate)\n",
    "    return [new_w,new_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0QEmWtux2hqc"
   },
   "outputs": [],
   "source": [
    "def error(w,b,lamb,data):\n",
    "    totalError=0\n",
    "    matric=w.T.dot(b)\n",
    "    for i in range(0,data.shape[0]):\n",
    "        for j in range(0,data.shape[1]):\n",
    "            if data[i][j]!=0:\n",
    "                totalError+=(data[i][j]-matric[i][j])**2\n",
    "    totalError+=lamb*(w.dot(w.T)+b.dot(b.T))\n",
    "    return totalError[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vEjIlgGi4dlj"
   },
   "outputs": [],
   "source": [
    "def rmse(data, Q, P):\n",
    "    I = data != 0  # Indicator function which is zero for missing data\n",
    "    ME = I * (data - np.dot(Q.T, P))  # Errors between real and predicted ratings\n",
    "    MSE = ME**2  \n",
    "    return np.sqrt(np.sum(MSE)/np.sum(I))  # sum of squared errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HFnAUQzY54WD"
   },
   "outputs": [],
   "source": [
    "def minbatch_gradient_descent_runner1(data,starting_w,starting_b,minbatch,learning_rate,lamb,max_iterations):\n",
    "    b=starting_b\n",
    "    w=starting_w\n",
    "    lasterror = 0\n",
    "    row,column=data.nonzero()\n",
    "    zero=np.zeros(data.shape)\n",
    "    partial_root_mean_square_error=[]\n",
    "    \n",
    "    random.seed(10)\n",
    "    group_index=[[row[l],column[l]] for l in range(len(row))]\n",
    "    v=0\n",
    "    group=[]\n",
    "    while v < row.shape[0]:\n",
    "      group.append(group_index[v:v+minbatch])\n",
    "      v+=minbatch\n",
    "    group=np.array(group)\n",
    "    ##group[k][l][m]=> k-th group l-th data m=0 =>row m=1 =>column\n",
    "    \n",
    "    for j in range(max_iterations):\n",
    "      for i in range(0,group.shape[0]):\n",
    "        zero=np.zeros(data.shape)\n",
    "        w,b=minbatch_partial_step_gradient1(w,b,data,i,learning_rate,lamb)\n",
    "      partial_root_mean_square_error.append(rmse(data, w, b))\n",
    "      print(\"The {}-th iteration rmse = {}\".format(j+1,rmse(data, w, b)))\n",
    "      print(\"------------------------------\")\n",
    "      if np.abs(error(w,b,lamb,data)-lasterror)>0.1:\n",
    "        lasterror=error(w,b,lamb,data)\n",
    "      else:\n",
    "        break\n",
    "    return partial_root_mean_square_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-m7MDbWW2Hf8",
    "outputId": "df3f0b89-0667-4df6-8752-f959e80dc963"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 1-th iteration rmse = 1.6329030236470643\n",
      "------------------------------\n",
      "The 2-th iteration rmse = 1.549023943312436\n",
      "------------------------------\n",
      "The 3-th iteration rmse = 1.6595376726635387\n",
      "------------------------------\n",
      "The 4-th iteration rmse = 1.890747261958489\n",
      "------------------------------\n",
      "The 5-th iteration rmse = 2.2082854003047205\n",
      "------------------------------\n",
      "The 6-th iteration rmse = 2.521898379497624\n",
      "------------------------------\n",
      "The 7-th iteration rmse = 2.693303242412501\n",
      "------------------------------\n",
      "The 8-th iteration rmse = 2.5244794464540354\n",
      "------------------------------\n",
      "The 9-th iteration rmse = 2.0716830665939248\n",
      "------------------------------\n",
      "The 10-th iteration rmse = 1.5497834415816243\n",
      "------------------------------\n",
      "The 11-th iteration rmse = 1.2329619109244119\n",
      "------------------------------\n",
      "The 12-th iteration rmse = 1.091902656529898\n",
      "------------------------------\n",
      "The 13-th iteration rmse = 1.0386485778023238\n",
      "------------------------------\n",
      "The 14-th iteration rmse = 1.0159339465467436\n",
      "------------------------------\n",
      "The 15-th iteration rmse = 1.0041572255790914\n",
      "------------------------------\n",
      "The 16-th iteration rmse = 0.9963814284277419\n",
      "------------------------------\n",
      "The 17-th iteration rmse = 0.9904824630280189\n",
      "------------------------------\n",
      "The 18-th iteration rmse = 0.9855558092778827\n",
      "------------------------------\n",
      "The 19-th iteration rmse = 0.9813056582043479\n",
      "------------------------------\n",
      "The 20-th iteration rmse = 0.9775278916790339\n",
      "------------------------------\n",
      "The 21-th iteration rmse = 0.974147458877406\n",
      "------------------------------\n",
      "The 22-th iteration rmse = 0.9710822442385441\n",
      "------------------------------\n",
      "The 23-th iteration rmse = 0.9682969623515614\n",
      "------------------------------\n",
      "The 24-th iteration rmse = 0.9657460057535793\n",
      "------------------------------\n",
      "The 25-th iteration rmse = 0.9634066161101351\n",
      "------------------------------\n",
      "The 26-th iteration rmse = 0.9612495479920798\n",
      "------------------------------\n",
      "The 27-th iteration rmse = 0.9592582406458896\n",
      "------------------------------\n",
      "The 28-th iteration rmse = 0.957412498117962\n",
      "------------------------------\n",
      "The 29-th iteration rmse = 0.9556996443762164\n",
      "------------------------------\n",
      "The 30-th iteration rmse = 0.9541050683123261\n",
      "------------------------------\n",
      "The 31-th iteration rmse = 0.9526188129795565\n",
      "------------------------------\n",
      "The 32-th iteration rmse = 0.951229953096108\n",
      "------------------------------\n",
      "The 33-th iteration rmse = 0.9499305425600246\n",
      "------------------------------\n",
      "The 34-th iteration rmse = 0.9487122049139037\n",
      "------------------------------\n",
      "The 35-th iteration rmse = 0.9475685270423606\n",
      "------------------------------\n",
      "The 36-th iteration rmse = 0.9464929579272565\n",
      "------------------------------\n",
      "The 37-th iteration rmse = 0.9454802752356731\n",
      "------------------------------\n",
      "The 38-th iteration rmse = 0.9445252718380523\n",
      "------------------------------\n",
      "The 39-th iteration rmse = 0.9436236623892237\n",
      "------------------------------\n",
      "The 40-th iteration rmse = 0.9427712515030177\n",
      "------------------------------\n",
      "The 41-th iteration rmse = 0.9419644984389434\n",
      "------------------------------\n",
      "The 42-th iteration rmse = 0.9411999837663472\n",
      "------------------------------\n",
      "The 43-th iteration rmse = 0.9404747633445509\n",
      "------------------------------\n",
      "The 44-th iteration rmse = 0.9397860222552759\n",
      "------------------------------\n",
      "The 45-th iteration rmse = 0.9391312978367361\n",
      "------------------------------\n",
      "The 46-th iteration rmse = 0.9385082524708345\n",
      "------------------------------\n",
      "The 47-th iteration rmse = 0.937914814634718\n",
      "------------------------------\n",
      "The 48-th iteration rmse = 0.9373490279621045\n",
      "------------------------------\n",
      "The 49-th iteration rmse = 0.9368091406335851\n",
      "------------------------------\n",
      "The 50-th iteration rmse = 0.9362935039164645\n",
      "------------------------------\n",
      "The 51-th iteration rmse = 0.9358006288200756\n",
      "------------------------------\n",
      "The 52-th iteration rmse = 0.9353291170742739\n",
      "------------------------------\n",
      "The 53-th iteration rmse = 0.9348776969485679\n",
      "------------------------------\n",
      "The 54-th iteration rmse = 0.9344451757231331\n",
      "------------------------------\n",
      "The 55-th iteration rmse = 0.9340304622009447\n",
      "------------------------------\n",
      "The 56-th iteration rmse = 0.9336325335699516\n",
      "------------------------------\n",
      "The 57-th iteration rmse = 0.9332504493997731\n",
      "------------------------------\n",
      "The 58-th iteration rmse = 0.9328833282430393\n",
      "------------------------------\n",
      "The 59-th iteration rmse = 0.9325303561810505\n",
      "------------------------------\n",
      "The 60-th iteration rmse = 0.9321907700873489\n",
      "------------------------------\n",
      "The 61-th iteration rmse = 0.9318638626901238\n",
      "------------------------------\n",
      "The 62-th iteration rmse = 0.9315489704432133\n",
      "------------------------------\n",
      "The 63-th iteration rmse = 0.9312454763727349\n",
      "------------------------------\n",
      "The 64-th iteration rmse = 0.9309528011700335\n",
      "------------------------------\n",
      "The 65-th iteration rmse = 0.9306704046404879\n",
      "------------------------------\n",
      "The 66-th iteration rmse = 0.9303977790751237\n",
      "------------------------------\n",
      "The 67-th iteration rmse = 0.9301344498296994\n",
      "------------------------------\n",
      "The 68-th iteration rmse = 0.9298799703264637\n",
      "------------------------------\n",
      "The 69-th iteration rmse = 0.9296339221040513\n",
      "------------------------------\n",
      "The 70-th iteration rmse = 0.9293959109990636\n",
      "------------------------------\n",
      "The 71-th iteration rmse = 0.9291655668855822\n",
      "------------------------------\n",
      "The 72-th iteration rmse = 0.9289425407207261\n",
      "------------------------------\n",
      "The 73-th iteration rmse = 0.9287265041134491\n",
      "------------------------------\n",
      "The 74-th iteration rmse = 0.928517147010275\n",
      "------------------------------\n",
      "The 75-th iteration rmse = 0.9283141771815638\n",
      "------------------------------\n",
      "The 76-th iteration rmse = 0.9281173183871998\n",
      "------------------------------\n",
      "The 77-th iteration rmse = 0.9279263098350564\n",
      "------------------------------\n",
      "The 78-th iteration rmse = 0.9277409047107265\n",
      "------------------------------\n",
      "The 79-th iteration rmse = 0.9275608696412243\n",
      "------------------------------\n",
      "The 80-th iteration rmse = 0.9273859835040229\n",
      "------------------------------\n",
      "The 81-th iteration rmse = 0.9272160369150557\n",
      "------------------------------\n",
      "The 82-th iteration rmse = 0.9270508312544479\n",
      "------------------------------\n",
      "The 83-th iteration rmse = 0.9268901781889535\n",
      "------------------------------\n",
      "The 84-th iteration rmse = 0.9267338988676322\n",
      "------------------------------\n",
      "The 85-th iteration rmse = 0.9265818234832266\n",
      "------------------------------\n",
      "The 86-th iteration rmse = 0.9264337906025065\n",
      "------------------------------\n",
      "The 87-th iteration rmse = 0.9262896467676158\n",
      "------------------------------\n",
      "The 88-th iteration rmse = 0.9261492459341966\n",
      "------------------------------\n",
      "The 89-th iteration rmse = 0.9260124491116704\n",
      "------------------------------\n",
      "The 90-th iteration rmse = 0.9258791238884172\n",
      "------------------------------\n",
      "The 91-th iteration rmse = 0.9257491441087979\n",
      "------------------------------\n",
      "The 92-th iteration rmse = 0.9256223894692747\n",
      "------------------------------\n",
      "The 93-th iteration rmse = 0.9254987452293766\n",
      "------------------------------\n",
      "The 94-th iteration rmse = 0.9253781018661209\n",
      "------------------------------\n",
      "The 95-th iteration rmse = 0.9252603548158956\n",
      "------------------------------\n",
      "The 96-th iteration rmse = 0.9251454041771485\n",
      "------------------------------\n",
      "The 97-th iteration rmse = 0.9250331544801805\n",
      "------------------------------\n",
      "The 98-th iteration rmse = 0.9249235144300719\n",
      "------------------------------\n",
      "The 99-th iteration rmse = 0.9248163967014881\n",
      "------------------------------\n",
      "The 100-th iteration rmse = 0.9247117177153849\n",
      "------------------------------\n",
      "The 101-th iteration rmse = 0.9246093974561184\n",
      "------------------------------\n",
      "The 102-th iteration rmse = 0.9245093592766779\n",
      "------------------------------\n",
      "The 103-th iteration rmse = 0.9244115297356257\n",
      "------------------------------\n",
      "The 104-th iteration rmse = 0.9243158384265524\n",
      "------------------------------\n",
      "The 105-th iteration rmse = 0.9242222178326113\n",
      "------------------------------\n",
      "The 106-th iteration rmse = 0.9241306031766486\n",
      "------------------------------\n",
      "The 107-th iteration rmse = 0.9240409322913287\n",
      "------------------------------\n",
      "The 108-th iteration rmse = 0.9239531454869933\n",
      "------------------------------\n",
      "The 109-th iteration rmse = 0.9238671854355919\n",
      "------------------------------\n",
      "The 110-th iteration rmse = 0.9237829970538153\n",
      "------------------------------\n",
      "The 111-th iteration rmse = 0.9237005273992438\n",
      "------------------------------\n",
      "The 112-th iteration rmse = 0.9236197255666957\n",
      "------------------------------\n",
      "The 113-th iteration rmse = 0.9235405425951918\n",
      "------------------------------\n",
      "The 114-th iteration rmse = 0.9234629313757758\n",
      "------------------------------\n",
      "The 115-th iteration rmse = 0.923386846568063\n",
      "------------------------------\n",
      "The 116-th iteration rmse = 0.9233122445180584\n",
      "------------------------------\n",
      "The 117-th iteration rmse = 0.9232390831831963\n",
      "------------------------------\n",
      "The 118-th iteration rmse = 0.9231673220588994\n",
      "------------------------------\n",
      "The 119-th iteration rmse = 0.9230969221111565\n",
      "------------------------------\n",
      "The 120-th iteration rmse = 0.9230278457107403\n",
      "------------------------------\n",
      "The 121-th iteration rmse = 0.9229600565724838\n",
      "------------------------------\n",
      "The 122-th iteration rmse = 0.9228935196962318\n",
      "------------------------------\n",
      "The 123-th iteration rmse = 0.9228282013120754\n",
      "------------------------------\n",
      "The 124-th iteration rmse = 0.9227640688272398\n",
      "------------------------------\n",
      "The 125-th iteration rmse = 0.9227010907766214\n",
      "------------------------------\n",
      "The 126-th iteration rmse = 0.922639236774923\n",
      "------------------------------\n",
      "The 127-th iteration rmse = 0.9225784774719225\n",
      "------------------------------\n",
      "The 128-th iteration rmse = 0.9225187845092575\n",
      "------------------------------\n",
      "The 129-th iteration rmse = 0.9224601304799088\n",
      "------------------------------\n",
      "The 130-th iteration rmse = 0.9224024888891216\n",
      "------------------------------\n",
      "The 131-th iteration rmse = 0.9223458341176577\n",
      "------------------------------\n",
      "The 132-th iteration rmse = 0.9222901413863938\n",
      "------------------------------\n",
      "The 133-th iteration rmse = 0.9222353867229479\n",
      "------------------------------\n",
      "The 134-th iteration rmse = 0.922181546929559\n",
      "------------------------------\n",
      "The 135-th iteration rmse = 0.9221285995527367\n",
      "------------------------------\n",
      "The 136-th iteration rmse = 0.9220765228540717\n",
      "------------------------------\n",
      "The 137-th iteration rmse = 0.9220252957826003\n",
      "------------------------------\n",
      "The 138-th iteration rmse = 0.9219748979482387\n",
      "------------------------------\n",
      "The 139-th iteration rmse = 0.9219253095965878\n",
      "------------------------------\n",
      "The 140-th iteration rmse = 0.9218765115847193\n",
      "------------------------------\n",
      "The 141-th iteration rmse = 0.9218284853581776\n",
      "------------------------------\n",
      "The 142-th iteration rmse = 0.9217812129288813\n",
      "------------------------------\n",
      "The 143-th iteration rmse = 0.9217346768541002\n",
      "------------------------------\n",
      "The 144-th iteration rmse = 0.9216888602162612\n",
      "------------------------------\n",
      "The 145-th iteration rmse = 0.9216437466037138\n",
      "------------------------------\n",
      "The 146-th iteration rmse = 0.9215993200922455\n",
      "------------------------------\n",
      "The 147-th iteration rmse = 0.921555565227465\n",
      "------------------------------\n",
      "The 148-th iteration rmse = 0.921512467007866\n",
      "------------------------------\n",
      "The 149-th iteration rmse = 0.921470010868665\n",
      "------------------------------\n",
      "The 150-th iteration rmse = 0.92142818266627\n",
      "------------------------------\n",
      "The 151-th iteration rmse = 0.9213869686634384\n",
      "------------------------------\n",
      "The 152-th iteration rmse = 0.9213463555150142\n",
      "------------------------------\n",
      "The 153-th iteration rmse = 0.9213063302542847\n",
      "------------------------------\n",
      "The 154-th iteration rmse = 0.9212668802798639\n",
      "------------------------------\n",
      "The 155-th iteration rmse = 0.9212279933431423\n",
      "------------------------------\n",
      "The 156-th iteration rmse = 0.921189657536213\n",
      "------------------------------\n",
      "The 157-th iteration rmse = 0.9211518612803078\n",
      "------------------------------\n",
      "The 158-th iteration rmse = 0.921114593314676\n",
      "------------------------------\n",
      "The 159-th iteration rmse = 0.9210778426859209\n",
      "------------------------------\n",
      "The 160-th iteration rmse = 0.9210415987377385\n",
      "------------------------------\n",
      "The 161-th iteration rmse = 0.9210058511010785\n",
      "------------------------------\n",
      "The 162-th iteration rmse = 0.9209705896846698\n",
      "------------------------------\n",
      "The 163-th iteration rmse = 0.9209358046659282\n",
      "------------------------------\n",
      "The 164-th iteration rmse = 0.9209014864822026\n",
      "------------------------------\n",
      "The 165-th iteration rmse = 0.9208676258223639\n",
      "------------------------------\n",
      "The 166-th iteration rmse = 0.9208342136187087\n",
      "------------------------------\n",
      "The 167-th iteration rmse = 0.9208012410391753\n",
      "------------------------------\n",
      "The 168-th iteration rmse = 0.9207686994798429\n",
      "------------------------------\n",
      "The 169-th iteration rmse = 0.9207365805577233\n",
      "------------------------------\n",
      "The 170-th iteration rmse = 0.9207048761038085\n",
      "------------------------------\n",
      "The 171-th iteration rmse = 0.9206735781563857\n",
      "------------------------------\n",
      "The 172-th iteration rmse = 0.9206426789545904\n",
      "------------------------------\n",
      "The 173-th iteration rmse = 0.9206121709321985\n",
      "------------------------------\n",
      "The 174-th iteration rmse = 0.9205820467116449\n",
      "------------------------------\n",
      "The 175-th iteration rmse = 0.9205522990982566\n",
      "------------------------------\n",
      "The 176-th iteration rmse = 0.9205229210746911\n",
      "------------------------------\n",
      "The 177-th iteration rmse = 0.9204939057955814\n",
      "------------------------------\n",
      "The 178-th iteration rmse = 0.9204652465823593\n",
      "------------------------------\n",
      "The 179-th iteration rmse = 0.9204369369182743\n",
      "------------------------------\n",
      "The 180-th iteration rmse = 0.9204089704435784\n",
      "------------------------------\n",
      "The 181-th iteration rmse = 0.9203813409508851\n",
      "------------------------------\n",
      "The 182-th iteration rmse = 0.9203540423806857\n",
      "------------------------------\n",
      "The 183-th iteration rmse = 0.9203270688170242\n",
      "------------------------------\n",
      "The 184-th iteration rmse = 0.9203004144833203\n",
      "------------------------------\n",
      "The 185-th iteration rmse = 0.9202740737383319\n",
      "------------------------------\n",
      "The 186-th iteration rmse = 0.9202480410722627\n",
      "------------------------------\n",
      "The 187-th iteration rmse = 0.9202223111029934\n",
      "------------------------------\n",
      "The 188-th iteration rmse = 0.9201968785724456\n",
      "------------------------------\n",
      "The 189-th iteration rmse = 0.9201717383430672\n",
      "------------------------------\n",
      "The 190-th iteration rmse = 0.9201468853944301\n",
      "------------------------------\n",
      "The 191-th iteration rmse = 0.9201223148199509\n",
      "------------------------------\n",
      "The 192-th iteration rmse = 0.9200980218237059\n",
      "------------------------------\n",
      "The 193-th iteration rmse = 0.9200740017173663\n",
      "------------------------------\n",
      "The 194-th iteration rmse = 0.9200502499172217\n",
      "------------------------------\n",
      "The 195-th iteration rmse = 0.9200267619413063\n",
      "------------------------------\n",
      "The 196-th iteration rmse = 0.9200035334066159\n",
      "------------------------------\n",
      "The 197-th iteration rmse = 0.9199805600264178\n",
      "------------------------------\n",
      "The 198-th iteration rmse = 0.9199578376076424\n",
      "------------------------------\n",
      "The 199-th iteration rmse = 0.9199353620483618\n",
      "------------------------------\n",
      "The 200-th iteration rmse = 0.9199131293353464\n",
      "------------------------------\n",
      "The 201-th iteration rmse = 0.9198911355417004\n",
      "------------------------------\n",
      "The 202-th iteration rmse = 0.9198693768245692\n",
      "------------------------------\n",
      "The 203-th iteration rmse = 0.9198478494229221\n",
      "------------------------------\n",
      "The 204-th iteration rmse = 0.9198265496554012\n",
      "------------------------------\n",
      "The 205-th iteration rmse = 0.9198054739182387\n",
      "------------------------------\n",
      "The 206-th iteration rmse = 0.9197846186832365\n",
      "------------------------------\n",
      "The 207-th iteration rmse = 0.9197639804958091\n",
      "------------------------------\n",
      "The 208-th iteration rmse = 0.9197435559730902\n",
      "------------------------------\n",
      "The 209-th iteration rmse = 0.9197233418020878\n",
      "------------------------------\n",
      "The 210-th iteration rmse = 0.9197033347379056\n",
      "------------------------------\n",
      "The 211-th iteration rmse = 0.9196835316020082\n",
      "------------------------------\n",
      "The 212-th iteration rmse = 0.9196639292805481\n",
      "------------------------------\n",
      "The 213-th iteration rmse = 0.9196445247227337\n",
      "------------------------------\n",
      "The 214-th iteration rmse = 0.919625314939253\n",
      "------------------------------\n",
      "The 215-th iteration rmse = 0.9196062970007406\n",
      "------------------------------\n",
      "The 216-th iteration rmse = 0.9195874680362879\n",
      "------------------------------\n",
      "The 217-th iteration rmse = 0.9195688252320011\n",
      "------------------------------\n",
      "The 218-th iteration rmse = 0.9195503658296023\n",
      "------------------------------\n",
      "The 219-th iteration rmse = 0.9195320871250635\n",
      "------------------------------\n",
      "The 220-th iteration rmse = 0.919513986467289\n",
      "------------------------------\n",
      "The 221-th iteration rmse = 0.9194960612568307\n",
      "------------------------------\n",
      "The 222-th iteration rmse = 0.9194783089446423\n",
      "------------------------------\n",
      "The 223-th iteration rmse = 0.9194607270308671\n",
      "------------------------------\n",
      "The 224-th iteration rmse = 0.9194433130636644\n",
      "------------------------------\n",
      "The 225-th iteration rmse = 0.9194260646380643\n",
      "------------------------------\n",
      "The 226-th iteration rmse = 0.9194089793948561\n",
      "------------------------------\n",
      "The 227-th iteration rmse = 0.9193920550195119\n",
      "------------------------------\n",
      "The 228-th iteration rmse = 0.9193752892411343\n",
      "------------------------------\n",
      "The 229-th iteration rmse = 0.9193586798314379\n",
      "------------------------------\n",
      "The 230-th iteration rmse = 0.9193422246037554\n",
      "------------------------------\n",
      "The 231-th iteration rmse = 0.9193259214120758\n",
      "------------------------------\n",
      "The 232-th iteration rmse = 0.9193097681501055\n",
      "------------------------------\n",
      "The 233-th iteration rmse = 0.9192937627503535\n",
      "------------------------------\n",
      "The 234-th iteration rmse = 0.9192779031832481\n",
      "------------------------------\n",
      "The 235-th iteration rmse = 0.9192621874562694\n",
      "------------------------------\n",
      "The 236-th iteration rmse = 0.919246613613113\n",
      "------------------------------\n",
      "The 237-th iteration rmse = 0.9192311797328694\n",
      "------------------------------\n",
      "The 238-th iteration rmse = 0.9192158839292311\n",
      "------------------------------\n",
      "The 239-th iteration rmse = 0.9192007243497166\n",
      "------------------------------\n",
      "The 240-th iteration rmse = 0.9191856991749162\n",
      "------------------------------\n",
      "The 241-th iteration rmse = 0.919170806617761\n",
      "------------------------------\n",
      "The 242-th iteration rmse = 0.9191560449228051\n",
      "------------------------------\n",
      "The 243-th iteration rmse = 0.9191414123655326\n",
      "------------------------------\n",
      "The 244-th iteration rmse = 0.9191269072516781\n",
      "------------------------------\n",
      "The 245-th iteration rmse = 0.919112527916569\n",
      "------------------------------\n",
      "The 246-th iteration rmse = 0.9190982727244812\n",
      "------------------------------\n",
      "The 247-th iteration rmse = 0.9190841400680123\n",
      "------------------------------\n",
      "The 248-th iteration rmse = 0.919070128367474\n",
      "------------------------------\n",
      "The 249-th iteration rmse = 0.9190562360702959\n",
      "------------------------------\n",
      "The 250-th iteration rmse = 0.919042461650447\n",
      "------------------------------\n",
      "The 251-th iteration rmse = 0.9190288036078702\n",
      "------------------------------\n",
      "The 252-th iteration rmse = 0.9190152604679344\n",
      "------------------------------\n",
      "The 253-th iteration rmse = 0.9190018307808944\n",
      "------------------------------\n",
      "The 254-th iteration rmse = 0.9189885131213731\n",
      "------------------------------\n",
      "The 255-th iteration rmse = 0.9189753060878454\n",
      "------------------------------\n",
      "The 256-th iteration rmse = 0.9189622083021481\n",
      "------------------------------\n",
      "The 257-th iteration rmse = 0.9189492184089894\n",
      "------------------------------\n",
      "The 258-th iteration rmse = 0.9189363350754794\n",
      "------------------------------\n",
      "The 259-th iteration rmse = 0.9189235569906672\n",
      "------------------------------\n",
      "The 260-th iteration rmse = 0.918910882865092\n",
      "------------------------------\n",
      "The 261-th iteration rmse = 0.9188983114303455\n",
      "------------------------------\n",
      "The 262-th iteration rmse = 0.9188858414386396\n",
      "------------------------------\n",
      "The 263-th iteration rmse = 0.918873471662394\n",
      "------------------------------\n",
      "The 264-th iteration rmse = 0.9188612008938253\n",
      "------------------------------\n",
      "The 265-th iteration rmse = 0.9188490279445486\n",
      "------------------------------\n",
      "The 266-th iteration rmse = 0.9188369516451919\n",
      "------------------------------\n",
      "The 267-th iteration rmse = 0.9188249708450146\n",
      "------------------------------\n",
      "The 268-th iteration rmse = 0.9188130844115383\n",
      "------------------------------\n",
      "The 269-th iteration rmse = 0.9188012912301862\n",
      "------------------------------\n",
      "The 270-th iteration rmse = 0.9187895902039287\n",
      "------------------------------\n",
      "The 271-th iteration rmse = 0.918777980252941\n",
      "------------------------------\n",
      "The 272-th iteration rmse = 0.9187664603142649\n",
      "------------------------------\n",
      "The 273-th iteration rmse = 0.9187550293414817\n",
      "------------------------------\n",
      "The 274-th iteration rmse = 0.9187436863043903\n",
      "------------------------------\n",
      "The 275-th iteration rmse = 0.9187324301886938\n",
      "------------------------------\n",
      "The 276-th iteration rmse = 0.9187212599956943\n",
      "------------------------------\n",
      "The 277-th iteration rmse = 0.9187101747419917\n",
      "------------------------------\n",
      "The 278-th iteration rmse = 0.9186991734591939\n",
      "------------------------------\n",
      "The 279-th iteration rmse = 0.9186882551936297\n",
      "------------------------------\n",
      "The 280-th iteration rmse = 0.9186774190060688\n",
      "------------------------------\n",
      "The 281-th iteration rmse = 0.9186666639714508\n",
      "------------------------------\n",
      "The 282-th iteration rmse = 0.9186559891786179\n",
      "------------------------------\n",
      "The 283-th iteration rmse = 0.9186453937300529\n",
      "------------------------------\n",
      "The 284-th iteration rmse = 0.9186348767416266\n",
      "------------------------------\n",
      "The 285-th iteration rmse = 0.9186244373423462\n",
      "------------------------------\n",
      "The 286-th iteration rmse = 0.9186140746741153\n",
      "------------------------------\n",
      "The 287-th iteration rmse = 0.9186037878914898\n",
      "------------------------------\n",
      "The 288-th iteration rmse = 0.9185935761614519\n",
      "------------------------------\n",
      "The 289-th iteration rmse = 0.918583438663177\n",
      "------------------------------\n",
      "The 290-th iteration rmse = 0.9185733745878136\n",
      "------------------------------\n",
      "The 291-th iteration rmse = 0.918563383138263\n",
      "------------------------------\n",
      "The 292-th iteration rmse = 0.9185534635289699\n",
      "------------------------------\n",
      "The 293-th iteration rmse = 0.9185436149857101\n",
      "------------------------------\n",
      "The 294-th iteration rmse = 0.9185338367453871\n",
      "------------------------------\n",
      "The 295-th iteration rmse = 0.9185241280558352\n",
      "------------------------------\n",
      "The 296-th iteration rmse = 0.9185144881756195\n",
      "------------------------------\n",
      "The 297-th iteration rmse = 0.9185049163738497\n",
      "------------------------------\n",
      "The 298-th iteration rmse = 0.9184954119299881\n",
      "------------------------------\n",
      "The 299-th iteration rmse = 0.9184859741336712\n",
      "------------------------------\n",
      "The 300-th iteration rmse = 0.9184766022845259\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "minbatch=10000\n",
    "w=np.array([[2]*data.shape[0]])\n",
    "b=np.array([[3]*data.shape[1]])\n",
    "lamb=0.01\n",
    "learning_rate=0.0004\n",
    "max_iterations=300\n",
    "row,column=data.nonzero()\n",
    "minbatch_root_mean_square_error=minbatch_gradient_descent_runner1(data,w,b,minbatch,learning_rate,lamb,max_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uS2BXdTBLN3y"
   },
   "source": [
    "## **Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "STSINnXNOr44"
   },
   "outputs": [],
   "source": [
    "def residual(data,w,b):\n",
    "    I = data != 0  # Indicator function which is zero for missing data\n",
    "    ME = I * (data - np.dot(w.T, b))  # Errors between real and predicted ratings  \n",
    "    return  ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5hyDB4GOOVYK"
   },
   "outputs": [],
   "source": [
    "def step_gradient1(w,b,data,learning_rate,lamb):\n",
    "    w_gradient=(residual(data,w,b).dot(b.T).T-w*lamb)\n",
    "    b_gradient=(residual(data,w,b).T.dot(w.T).T-b*lamb)\n",
    "    new_w=w+(w_gradient*learning_rate)\n",
    "    new_b=b+(b_gradient*learning_rate)\n",
    "    return [new_w,new_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0zIX99BtOz3A"
   },
   "outputs": [],
   "source": [
    "def error(w,b,lamb,data):\n",
    "    totalError=0\n",
    "    matric=w.T.dot(b)\n",
    "    for i in range(0,data.shape[0]):\n",
    "        for j in range(0,data.shape[1]):\n",
    "            if data[i][j]!=0:\n",
    "                totalError+=(data[i][j]-matric[i][j])**2\n",
    "    totalError+=lamb*(w.dot(w.T)+b.dot(b.T))\n",
    "    return totalError[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pz2jOaKAO6fJ"
   },
   "outputs": [],
   "source": [
    "def rmse(data, Q, P):\n",
    "    I = data != 0  # Indicator function which is zero for missing data\n",
    "    ME = I * (data - np.dot(Q.T, P))  # Errors between real and predicted ratings\n",
    "    MSE = ME**2  \n",
    "    return np.sqrt(np.sum(MSE)/np.sum(I))  # sum of squared errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6r6qTScnLZdP"
   },
   "outputs": [],
   "source": [
    "def gradient_descent_runner1(data,starting_w,starting_b,learning_rate,lamb,max_iterations):\n",
    "    b=starting_b\n",
    "    w=starting_w\n",
    "    lasterror = 0\n",
    "    root_mean_square_error=[]\n",
    "    for i in range(max_iterations):\n",
    "        w,b=step_gradient1(w,b,data,learning_rate,lamb)\n",
    "        root_mean_square_error.append(rmse(data, w, b))\n",
    "        print(\"The {}-th iteration rmse = {}\".format(i+1,rmse(data, w, b)))\n",
    "        print(\"------------------------------\")\n",
    "        if np.abs(error(w,b,lamb,data)-lasterror)>0.1:\n",
    "          lasterror=error(w,b,lamb,data)\n",
    "        else:\n",
    "          break\n",
    "    return root_mean_square_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "g8pxG59dOMPr",
    "outputId": "8b002268-db92-4890-de9e-fe127535c240"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 1-th iteration rmse = 1.638008102859314\n",
      "------------------------------\n",
      "The 2-th iteration rmse = 1.5721357439436643\n",
      "------------------------------\n",
      "The 3-th iteration rmse = 1.7127699215283552\n",
      "------------------------------\n",
      "The 4-th iteration rmse = 1.9646243944425752\n",
      "------------------------------\n",
      "The 5-th iteration rmse = 2.299471049623312\n",
      "------------------------------\n",
      "The 6-th iteration rmse = 2.594620940215116\n",
      "------------------------------\n",
      "The 7-th iteration rmse = 2.7111985559629215\n",
      "------------------------------\n",
      "The 8-th iteration rmse = 2.4493117016333765\n",
      "------------------------------\n",
      "The 9-th iteration rmse = 1.9496050048977474\n",
      "------------------------------\n",
      "The 10-th iteration rmse = 1.4570512941563194\n",
      "------------------------------\n",
      "The 11-th iteration rmse = 1.1915658978945243\n",
      "------------------------------\n",
      "The 12-th iteration rmse = 1.078811060535889\n",
      "------------------------------\n",
      "The 13-th iteration rmse = 1.0346627648374405\n",
      "------------------------------\n",
      "The 14-th iteration rmse = 1.0144577393267036\n",
      "------------------------------\n",
      "The 15-th iteration rmse = 1.0031751884686448\n",
      "------------------------------\n",
      "The 16-th iteration rmse = 0.9955220348470295\n",
      "------------------------------\n",
      "The 17-th iteration rmse = 0.9896352925548947\n",
      "------------------------------\n",
      "The 18-th iteration rmse = 0.9847582965079859\n",
      "------------------------------\n",
      "The 19-th iteration rmse = 0.9805523811772082\n",
      "------------------------------\n",
      "The 20-th iteration rmse = 0.9768396630665402\n",
      "------------------------------\n",
      "The 21-th iteration rmse = 0.9735157320218522\n",
      "------------------------------\n",
      "The 22-th iteration rmse = 0.970511529511924\n",
      "------------------------------\n",
      "The 23-th iteration rmse = 0.9677779889050709\n",
      "------------------------------\n",
      "The 24-th iteration rmse = 0.9652778304321182\n",
      "------------------------------\n",
      "The 25-th iteration rmse = 0.9629816951731557\n",
      "------------------------------\n",
      "The 26-th iteration rmse = 0.9608656032230305\n",
      "------------------------------\n",
      "The 27-th iteration rmse = 0.9589096344040948\n",
      "------------------------------\n",
      "The 28-th iteration rmse = 0.9570968790246577\n",
      "------------------------------\n",
      "The 29-th iteration rmse = 0.9554128688219409\n",
      "------------------------------\n",
      "The 30-th iteration rmse = 0.9538450474378647\n",
      "------------------------------\n",
      "The 31-th iteration rmse = 0.9523824763986651\n",
      "------------------------------\n",
      "The 32-th iteration rmse = 0.9510155295814544\n",
      "------------------------------\n",
      "The 33-th iteration rmse = 0.9497357192646728\n",
      "------------------------------\n",
      "The 34-th iteration rmse = 0.9485355036961021\n",
      "------------------------------\n",
      "The 35-th iteration rmse = 0.9474081738721215\n",
      "------------------------------\n",
      "The 36-th iteration rmse = 0.9463477251127205\n",
      "------------------------------\n",
      "The 37-th iteration rmse = 0.9453487784921927\n",
      "------------------------------\n",
      "The 38-th iteration rmse = 0.9444064916430505\n",
      "------------------------------\n",
      "The 39-th iteration rmse = 0.9435165018646671\n",
      "------------------------------\n",
      "The 40-th iteration rmse = 0.9426748623408858\n",
      "------------------------------\n",
      "The 41-th iteration rmse = 0.9418779997378163\n",
      "------------------------------\n",
      "The 42-th iteration rmse = 0.9411226675504316\n",
      "------------------------------\n",
      "The 43-th iteration rmse = 0.9404059138435483\n",
      "------------------------------\n",
      "The 44-th iteration rmse = 0.9397250464911375\n",
      "------------------------------\n",
      "The 45-th iteration rmse = 0.9390776082533794\n",
      "------------------------------\n",
      "The 46-th iteration rmse = 0.9384613504688389\n",
      "------------------------------\n",
      "The 47-th iteration rmse = 0.9378742135641677\n",
      "------------------------------\n",
      "The 48-th iteration rmse = 0.9373143068716928\n",
      "------------------------------\n",
      "The 49-th iteration rmse = 0.9367798932344357\n",
      "------------------------------\n",
      "The 50-th iteration rmse = 0.9362693733366417\n",
      "------------------------------\n",
      "The 51-th iteration rmse = 0.9357812734394287\n",
      "------------------------------\n",
      "The 52-th iteration rmse = 0.9353142330847847\n",
      "------------------------------\n",
      "The 53-th iteration rmse = 0.9348669952518387\n",
      "------------------------------\n",
      "The 54-th iteration rmse = 0.9344383966152308\n",
      "------------------------------\n",
      "The 55-th iteration rmse = 0.9340273595910747\n",
      "------------------------------\n",
      "The 56-th iteration rmse = 0.9336328845519467\n",
      "------------------------------\n",
      "The 57-th iteration rmse = 0.9332540433603759\n",
      "------------------------------\n",
      "The 58-th iteration rmse = 0.9328899730982714\n",
      "------------------------------\n",
      "The 59-th iteration rmse = 0.9325398707800044\n",
      "------------------------------\n",
      "The 60-th iteration rmse = 0.9322029882651555\n",
      "------------------------------\n",
      "The 61-th iteration rmse = 0.9318786279132059\n",
      "------------------------------\n",
      "The 62-th iteration rmse = 0.9315661384288749\n",
      "------------------------------\n",
      "The 63-th iteration rmse = 0.9312649112730109\n",
      "------------------------------\n",
      "The 64-th iteration rmse = 0.9309743772487126\n",
      "------------------------------\n",
      "The 65-th iteration rmse = 0.9306940035229216\n",
      "------------------------------\n",
      "The 66-th iteration rmse = 0.9304232908052434\n",
      "------------------------------\n",
      "The 67-th iteration rmse = 0.9301617708652996\n",
      "------------------------------\n",
      "The 68-th iteration rmse = 0.9299090041889463\n",
      "------------------------------\n",
      "The 69-th iteration rmse = 0.9296645779000501\n",
      "------------------------------\n",
      "The 70-th iteration rmse = 0.9294281038036011\n",
      "------------------------------\n",
      "The 71-th iteration rmse = 0.9291992166389412\n",
      "------------------------------\n",
      "The 72-th iteration rmse = 0.9289775724382361\n",
      "------------------------------\n",
      "The 73-th iteration rmse = 0.9287628470525378\n",
      "------------------------------\n",
      "The 74-th iteration rmse = 0.92855473476869\n",
      "------------------------------\n",
      "The 75-th iteration rmse = 0.928352947060921\n",
      "------------------------------\n",
      "The 76-th iteration rmse = 0.9281572114205965\n",
      "------------------------------\n",
      "The 77-th iteration rmse = 0.9279672702949978\n",
      "------------------------------\n",
      "The 78-th iteration rmse = 0.9277828800932056\n",
      "------------------------------\n",
      "The 79-th iteration rmse = 0.9276038102808352\n",
      "------------------------------\n",
      "The 80-th iteration rmse = 0.9274298425323283\n",
      "------------------------------\n",
      "The 81-th iteration rmse = 0.9272607699561121\n",
      "------------------------------\n",
      "The 82-th iteration rmse = 0.9270963963691068\n",
      "------------------------------\n",
      "The 83-th iteration rmse = 0.9269365356313444\n",
      "------------------------------\n",
      "The 84-th iteration rmse = 0.9267810110229165\n",
      "------------------------------\n",
      "The 85-th iteration rmse = 0.9266296546707785\n",
      "------------------------------\n",
      "The 86-th iteration rmse = 0.9264823070118889\n",
      "------------------------------\n",
      "The 87-th iteration rmse = 0.9263388162979147\n",
      "------------------------------\n",
      "The 88-th iteration rmse = 0.9261990381311557\n",
      "------------------------------\n",
      "The 89-th iteration rmse = 0.9260628350352985\n",
      "------------------------------\n",
      "The 90-th iteration rmse = 0.9259300760530229\n",
      "------------------------------\n",
      "The 91-th iteration rmse = 0.9258006363729269\n",
      "------------------------------\n",
      "The 92-th iteration rmse = 0.9256743969795841\n",
      "------------------------------\n",
      "The 93-th iteration rmse = 0.9255512443283921\n",
      "------------------------------\n",
      "The 94-th iteration rmse = 0.9254310700403761\n",
      "------------------------------\n",
      "The 95-th iteration rmse = 0.9253137706180354\n",
      "------------------------------\n",
      "The 96-th iteration rmse = 0.9251992471784477\n",
      "------------------------------\n",
      "The 97-th iteration rmse = 0.9250874052042973\n",
      "------------------------------\n",
      "The 98-th iteration rmse = 0.9249781543098475\n",
      "------------------------------\n",
      "The 99-th iteration rmse = 0.9248714080222536\n",
      "------------------------------\n",
      "The 100-th iteration rmse = 0.9247670835758282\n",
      "------------------------------\n",
      "The 101-th iteration rmse = 0.9246651017194785\n",
      "------------------------------\n",
      "The 102-th iteration rmse = 0.9245653865354075\n",
      "------------------------------\n",
      "The 103-th iteration rmse = 0.9244678652691514\n",
      "------------------------------\n",
      "The 104-th iteration rmse = 0.9243724681694264\n",
      "------------------------------\n",
      "The 105-th iteration rmse = 0.9242791283377771\n",
      "------------------------------\n",
      "The 106-th iteration rmse = 0.9241877815867751\n",
      "------------------------------\n",
      "The 107-th iteration rmse = 0.9240983663067165\n",
      "------------------------------\n",
      "The 108-th iteration rmse = 0.9240108233397949\n",
      "------------------------------\n",
      "The 109-th iteration rmse = 0.9239250958616568\n",
      "------------------------------\n",
      "The 110-th iteration rmse = 0.9238411292695095\n",
      "------------------------------\n",
      "The 111-th iteration rmse = 0.9237588710766593\n",
      "------------------------------\n",
      "The 112-th iteration rmse = 0.9236782708128026\n",
      "------------------------------\n",
      "The 113-th iteration rmse = 0.9235992799299378\n",
      "------------------------------\n",
      "The 114-th iteration rmse = 0.9235218517133295\n",
      "------------------------------\n",
      "The 115-th iteration rmse = 0.9234459411974024\n",
      "------------------------------\n",
      "The 116-th iteration rmse = 0.923371505086084\n",
      "------------------------------\n",
      "The 117-th iteration rmse = 0.9232985016774807\n",
      "------------------------------\n",
      "The 118-th iteration rmse = 0.9232268907924733\n",
      "------------------------------\n",
      "The 119-th iteration rmse = 0.9231566337071289\n",
      "------------------------------\n",
      "The 120-th iteration rmse = 0.9230876930885873\n",
      "------------------------------\n",
      "The 121-th iteration rmse = 0.9230200329343008\n",
      "------------------------------\n",
      "The 122-th iteration rmse = 0.9229536185143633\n",
      "------------------------------\n",
      "The 123-th iteration rmse = 0.922888416316798\n",
      "------------------------------\n",
      "The 124-th iteration rmse = 0.9228243939955885\n",
      "------------------------------\n",
      "The 125-th iteration rmse = 0.9227615203213323\n",
      "------------------------------\n",
      "The 126-th iteration rmse = 0.9226997651343306\n",
      "------------------------------\n",
      "The 127-th iteration rmse = 0.9226390993000121\n",
      "------------------------------\n",
      "The 128-th iteration rmse = 0.9225794946665166\n",
      "------------------------------\n",
      "The 129-th iteration rmse = 0.9225209240243645\n",
      "------------------------------\n",
      "The 130-th iteration rmse = 0.9224633610680483\n",
      "------------------------------\n",
      "The 131-th iteration rmse = 0.922406780359484\n",
      "------------------------------\n",
      "The 132-th iteration rmse = 0.9223511572931783\n",
      "------------------------------\n",
      "The 133-th iteration rmse = 0.9222964680630589\n",
      "------------------------------\n",
      "The 134-th iteration rmse = 0.9222426896308398\n",
      "------------------------------\n",
      "The 135-th iteration rmse = 0.9221897996958726\n",
      "------------------------------\n",
      "The 136-th iteration rmse = 0.9221377766663758\n",
      "------------------------------\n",
      "The 137-th iteration rmse = 0.9220865996319929\n",
      "------------------------------\n",
      "The 138-th iteration rmse = 0.922036248337591\n",
      "------------------------------\n",
      "The 139-th iteration rmse = 0.921986703158249\n",
      "------------------------------\n",
      "The 140-th iteration rmse = 0.921937945075363\n",
      "------------------------------\n",
      "The 141-th iteration rmse = 0.9218899556538204\n",
      "------------------------------\n",
      "The 142-th iteration rmse = 0.9218427170201776\n",
      "------------------------------\n",
      "The 143-th iteration rmse = 0.9217962118418058\n",
      "------------------------------\n",
      "The 144-th iteration rmse = 0.9217504233069364\n",
      "------------------------------\n",
      "The 145-th iteration rmse = 0.9217053351055781\n",
      "------------------------------\n",
      "The 146-th iteration rmse = 0.9216609314112537\n",
      "------------------------------\n",
      "The 147-th iteration rmse = 0.9216171968635195\n",
      "------------------------------\n",
      "The 148-th iteration rmse = 0.9215741165512212\n",
      "------------------------------\n",
      "The 149-th iteration rmse = 0.9215316759964658\n",
      "------------------------------\n",
      "The 150-th iteration rmse = 0.9214898611392559\n",
      "------------------------------\n",
      "The 151-th iteration rmse = 0.9214486583227744\n",
      "------------------------------\n",
      "The 152-th iteration rmse = 0.9214080542792672\n",
      "------------------------------\n",
      "The 153-th iteration rmse = 0.9213680361165145\n",
      "------------------------------\n",
      "The 154-th iteration rmse = 0.9213285913048535\n",
      "------------------------------\n",
      "The 155-th iteration rmse = 0.921289707664725\n",
      "------------------------------\n",
      "The 156-th iteration rmse = 0.9212513733547237\n",
      "------------------------------\n",
      "The 157-th iteration rmse = 0.9212135768601332\n",
      "------------------------------\n",
      "The 158-th iteration rmse = 0.9211763069819076\n",
      "------------------------------\n",
      "The 159-th iteration rmse = 0.921139552826099\n",
      "------------------------------\n",
      "The 160-th iteration rmse = 0.9211033037936972\n",
      "------------------------------\n",
      "The 161-th iteration rmse = 0.9210675495708651\n",
      "------------------------------\n",
      "The 162-th iteration rmse = 0.9210322801195588\n",
      "------------------------------\n",
      "The 163-th iteration rmse = 0.9209974856685061\n",
      "------------------------------\n",
      "The 164-th iteration rmse = 0.9209631567045349\n",
      "------------------------------\n",
      "The 165-th iteration rmse = 0.9209292839642306\n",
      "------------------------------\n",
      "The 166-th iteration rmse = 0.920895858425912\n",
      "------------------------------\n",
      "The 167-th iteration rmse = 0.9208628713019074\n",
      "------------------------------\n",
      "The 168-th iteration rmse = 0.9208303140311267\n",
      "------------------------------\n",
      "The 169-th iteration rmse = 0.9207981782719056\n",
      "------------------------------\n",
      "The 170-th iteration rmse = 0.9207664558951145\n",
      "------------------------------\n",
      "The 171-th iteration rmse = 0.9207351389775282\n",
      "------------------------------\n",
      "The 172-th iteration rmse = 0.9207042197954325\n",
      "------------------------------\n",
      "The 173-th iteration rmse = 0.9206736908184667\n",
      "------------------------------\n",
      "The 174-th iteration rmse = 0.9206435447036911\n",
      "------------------------------\n",
      "The 175-th iteration rmse = 0.9206137742898655\n",
      "------------------------------\n",
      "The 176-th iteration rmse = 0.9205843725919346\n",
      "------------------------------\n",
      "The 177-th iteration rmse = 0.9205553327957119\n",
      "------------------------------\n",
      "The 178-th iteration rmse = 0.9205266482527501\n",
      "------------------------------\n",
      "The 179-th iteration rmse = 0.9204983124753926\n",
      "------------------------------\n",
      "The 180-th iteration rmse = 0.9204703191320003\n",
      "------------------------------\n",
      "The 181-th iteration rmse = 0.9204426620423456\n",
      "------------------------------\n",
      "The 182-th iteration rmse = 0.920415335173162\n",
      "------------------------------\n",
      "The 183-th iteration rmse = 0.9203883326338557\n",
      "------------------------------\n",
      "The 184-th iteration rmse = 0.9203616486723545\n",
      "------------------------------\n",
      "The 185-th iteration rmse = 0.9203352776711093\n",
      "------------------------------\n",
      "The 186-th iteration rmse = 0.9203092141432246\n",
      "------------------------------\n",
      "The 187-th iteration rmse = 0.9202834527287186\n",
      "------------------------------\n",
      "The 188-th iteration rmse = 0.9202579881909189\n",
      "------------------------------\n",
      "The 189-th iteration rmse = 0.9202328154129668\n",
      "------------------------------\n",
      "The 190-th iteration rmse = 0.9202079293944472\n",
      "------------------------------\n",
      "The 191-th iteration rmse = 0.9201833252481273\n",
      "------------------------------\n",
      "The 192-th iteration rmse = 0.9201589981968021\n",
      "------------------------------\n",
      "The 193-th iteration rmse = 0.9201349435702418\n",
      "------------------------------\n",
      "The 194-th iteration rmse = 0.9201111568022462\n",
      "------------------------------\n",
      "The 195-th iteration rmse = 0.9200876334277867\n",
      "------------------------------\n",
      "The 196-th iteration rmse = 0.9200643690802427\n",
      "------------------------------\n",
      "The 197-th iteration rmse = 0.9200413594887336\n",
      "------------------------------\n",
      "The 198-th iteration rmse = 0.9200186004755257\n",
      "------------------------------\n",
      "The 199-th iteration rmse = 0.9199960879535299\n",
      "------------------------------\n",
      "The 200-th iteration rmse = 0.9199738179238762\n",
      "------------------------------\n",
      "The 201-th iteration rmse = 0.9199517864735627\n",
      "------------------------------\n",
      "The 202-th iteration rmse = 0.9199299897731823\n",
      "------------------------------\n",
      "The 203-th iteration rmse = 0.9199084240747181\n",
      "------------------------------\n",
      "The 204-th iteration rmse = 0.9198870857094067\n",
      "------------------------------\n",
      "The 205-th iteration rmse = 0.9198659710856708\n",
      "------------------------------\n",
      "The 206-th iteration rmse = 0.9198450766871126\n",
      "------------------------------\n",
      "The 207-th iteration rmse = 0.9198243990705706\n",
      "------------------------------\n",
      "The 208-th iteration rmse = 0.9198039348642332\n",
      "------------------------------\n",
      "The 209-th iteration rmse = 0.9197836807658145\n",
      "------------------------------\n",
      "The 210-th iteration rmse = 0.9197636335407798\n",
      "------------------------------\n",
      "The 211-th iteration rmse = 0.9197437900206273\n",
      "------------------------------\n",
      "The 212-th iteration rmse = 0.9197241471012231\n",
      "------------------------------\n",
      "The 213-th iteration rmse = 0.919704701741181\n",
      "------------------------------\n",
      "The 214-th iteration rmse = 0.9196854509602953\n",
      "------------------------------\n",
      "The 215-th iteration rmse = 0.9196663918380182\n",
      "------------------------------\n",
      "The 216-th iteration rmse = 0.9196475215119794\n",
      "------------------------------\n",
      "The 217-th iteration rmse = 0.9196288371765549\n",
      "------------------------------\n",
      "The 218-th iteration rmse = 0.9196103360814721\n",
      "------------------------------\n",
      "The 219-th iteration rmse = 0.9195920155304574\n",
      "------------------------------\n",
      "The 220-th iteration rmse = 0.9195738728799231\n",
      "------------------------------\n",
      "The 221-th iteration rmse = 0.9195559055376932\n",
      "------------------------------\n",
      "The 222-th iteration rmse = 0.9195381109617644\n",
      "------------------------------\n",
      "The 223-th iteration rmse = 0.9195204866591008\n",
      "------------------------------\n",
      "The 224-th iteration rmse = 0.919503030184467\n",
      "------------------------------\n",
      "The 225-th iteration rmse = 0.9194857391392904\n",
      "------------------------------\n",
      "The 226-th iteration rmse = 0.9194686111705571\n",
      "------------------------------\n",
      "The 227-th iteration rmse = 0.9194516439697398\n",
      "------------------------------\n",
      "The 228-th iteration rmse = 0.9194348352717541\n",
      "------------------------------\n",
      "The 229-th iteration rmse = 0.9194181828539435\n",
      "------------------------------\n",
      "The 230-th iteration rmse = 0.9194016845350934\n",
      "------------------------------\n",
      "The 231-th iteration rmse = 0.9193853381744743\n",
      "------------------------------\n",
      "The 232-th iteration rmse = 0.9193691416709064\n",
      "------------------------------\n",
      "The 233-th iteration rmse = 0.9193530929618533\n",
      "------------------------------\n",
      "The 234-th iteration rmse = 0.9193371900225404\n",
      "------------------------------\n",
      "The 235-th iteration rmse = 0.9193214308650965\n",
      "------------------------------\n",
      "The 236-th iteration rmse = 0.9193058135377163\n",
      "------------------------------\n",
      "The 237-th iteration rmse = 0.9192903361238511\n",
      "------------------------------\n",
      "The 238-th iteration rmse = 0.919274996741413\n",
      "------------------------------\n",
      "The 239-th iteration rmse = 0.9192597935420104\n",
      "------------------------------\n",
      "The 240-th iteration rmse = 0.9192447247101941\n",
      "------------------------------\n",
      "The 241-th iteration rmse = 0.9192297884627276\n",
      "------------------------------\n",
      "The 242-th iteration rmse = 0.9192149830478803\n",
      "------------------------------\n",
      "The 243-th iteration rmse = 0.9192003067447329\n",
      "------------------------------\n",
      "The 244-th iteration rmse = 0.9191857578625012\n",
      "------------------------------\n",
      "The 245-th iteration rmse = 0.9191713347398858\n",
      "------------------------------\n",
      "The 246-th iteration rmse = 0.9191570357444266\n",
      "------------------------------\n",
      "The 247-th iteration rmse = 0.9191428592718847\n",
      "------------------------------\n",
      "The 248-th iteration rmse = 0.919128803745631\n",
      "------------------------------\n",
      "The 249-th iteration rmse = 0.9191148676160604\n",
      "------------------------------\n",
      "The 250-th iteration rmse = 0.9191010493600105\n",
      "------------------------------\n",
      "The 251-th iteration rmse = 0.9190873474802028\n",
      "------------------------------\n",
      "The 252-th iteration rmse = 0.9190737605046937\n",
      "------------------------------\n",
      "The 253-th iteration rmse = 0.9190602869863422\n",
      "------------------------------\n",
      "The 254-th iteration rmse = 0.9190469255022898\n",
      "------------------------------\n",
      "The 255-th iteration rmse = 0.9190336746534508\n",
      "------------------------------\n",
      "The 256-th iteration rmse = 0.9190205330640212\n",
      "------------------------------\n",
      "The 257-th iteration rmse = 0.9190074993809927\n",
      "------------------------------\n",
      "The 258-th iteration rmse = 0.9189945722736848\n",
      "------------------------------\n",
      "The 259-th iteration rmse = 0.9189817504332863\n",
      "------------------------------\n",
      "The 260-th iteration rmse = 0.9189690325724041\n",
      "------------------------------\n",
      "The 261-th iteration rmse = 0.9189564174246314\n",
      "------------------------------\n",
      "The 262-th iteration rmse = 0.9189439037441165\n",
      "------------------------------\n",
      "The 263-th iteration rmse = 0.9189314903051503\n",
      "------------------------------\n",
      "The 264-th iteration rmse = 0.9189191759017613\n",
      "------------------------------\n",
      "The 265-th iteration rmse = 0.9189069593473151\n",
      "------------------------------\n",
      "The 266-th iteration rmse = 0.9188948394741336\n",
      "------------------------------\n",
      "The 267-th iteration rmse = 0.9188828151331129\n",
      "------------------------------\n",
      "The 268-th iteration rmse = 0.9188708851933569\n",
      "------------------------------\n",
      "The 269-th iteration rmse = 0.9188590485418183\n",
      "------------------------------\n",
      "The 270-th iteration rmse = 0.9188473040829457\n",
      "------------------------------\n",
      "The 271-th iteration rmse = 0.9188356507383436\n",
      "------------------------------\n",
      "The 272-th iteration rmse = 0.9188240874464328\n",
      "------------------------------\n",
      "The 273-th iteration rmse = 0.918812613162128\n",
      "------------------------------\n",
      "The 274-th iteration rmse = 0.9188012268565159\n",
      "------------------------------\n",
      "The 275-th iteration rmse = 0.918789927516542\n",
      "------------------------------\n",
      "The 276-th iteration rmse = 0.9187787141447091\n",
      "------------------------------\n",
      "The 277-th iteration rmse = 0.9187675857587769\n",
      "------------------------------\n",
      "The 278-th iteration rmse = 0.9187565413914713\n",
      "------------------------------\n",
      "The 279-th iteration rmse = 0.9187455800901995\n",
      "------------------------------\n",
      "The 280-th iteration rmse = 0.9187347009167735\n",
      "------------------------------\n",
      "The 281-th iteration rmse = 0.918723902947136\n",
      "------------------------------\n",
      "The 282-th iteration rmse = 0.9187131852710979\n",
      "------------------------------\n",
      "The 283-th iteration rmse = 0.9187025469920761\n",
      "------------------------------\n",
      "The 284-th iteration rmse = 0.9186919872268401\n",
      "------------------------------\n",
      "The 285-th iteration rmse = 0.9186815051052651\n",
      "------------------------------\n",
      "The 286-th iteration rmse = 0.9186710997700883\n",
      "------------------------------\n",
      "The 287-th iteration rmse = 0.9186607703766715\n",
      "------------------------------\n",
      "The 288-th iteration rmse = 0.9186505160927697\n",
      "------------------------------\n",
      "The 289-th iteration rmse = 0.918640336098304\n",
      "------------------------------\n",
      "The 290-th iteration rmse = 0.918630229585139\n",
      "------------------------------\n",
      "The 291-th iteration rmse = 0.9186201957568663\n",
      "------------------------------\n",
      "The 292-th iteration rmse = 0.9186102338285923\n",
      "------------------------------\n",
      "The 293-th iteration rmse = 0.9186003430267295\n",
      "------------------------------\n",
      "The 294-th iteration rmse = 0.9185905225887944\n",
      "------------------------------\n",
      "The 295-th iteration rmse = 0.9185807717632065\n",
      "------------------------------\n",
      "The 296-th iteration rmse = 0.918571089809096\n",
      "------------------------------\n",
      "The 297-th iteration rmse = 0.9185614759961122\n",
      "------------------------------\n",
      "The 298-th iteration rmse = 0.9185519296042367\n",
      "------------------------------\n",
      "The 299-th iteration rmse = 0.9185424499236016\n",
      "------------------------------\n",
      "The 300-th iteration rmse = 0.9185330362543099\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "w=np.array([[2]*data.shape[0]])\n",
    "b=np.array([[3]*data.shape[1]])\n",
    "learning_rate=0.0004\n",
    "lamb=0.01\n",
    "max_iterations=300\n",
    "root_mean_square_error=gradient_descent_runner1(data,w,b,learning_rate,lamb,max_iterations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Imj9JOw9mETB"
   },
   "source": [
    "# **With Global Average Item Bias User Bias User-Item Interaction**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kCwqQaWTwg1p"
   },
   "source": [
    "$ \\hat\\gamma_{ui} = \\mu + b_i +b_u+ q^T _i  p_u  $\n",
    "\n",
    "$min_{q^*,p^*,b^*}\\sum_{(u,i)\\in\\kappa }{(\\gamma_{ui}-\\mu-b_i-b_u-q^T _i  p_u)^2} +\\lambda (||q_i||^2+||p_u||^2+b^2_i+b^2_u)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K4l3M-qUx_rD"
   },
   "source": [
    "其中：\n",
    "\n",
    "$b_i $: item biases $\\quad b_u$ : user biases $\\quad \\mu$ : overall average\n",
    "\n",
    "$\\gamma$ : user-item rating  $\\quad q_i$ :  item possesses those factors $\\quad p_u$ :  interest the user has in items that are high on the corresponding factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EJIQB-D7n8o0"
   },
   "source": [
    "## **With Gradient Descent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RaP5a8h89Jjy"
   },
   "source": [
    "$e_{ui}=\\gamma_{ui} - \\mu-b_i-b_u-q^T _i  p_u $\n",
    "*   $b_i \\leftarrow b_i+\\gamma \\cdot (e_{ui}\\cdot 1 - \\lambda \\cdot b_i)$\n",
    "*   $b_u \\leftarrow b_u+\\gamma \\cdot (e_{ui}\\cdot 1 - \\lambda \\cdot b_u)$\n",
    "*   $q_i \\leftarrow q_i+\\gamma \\cdot (e_{ui}\\cdot p_u - \\lambda \\cdot q_i)$\n",
    "*   $p_u \\leftarrow p_u+\\gamma \\cdot (e_{ui}\\cdot q_i - \\lambda \\cdot p_u)$\n",
    "\n",
    "其中 $\\gamma$ : learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "asIH2YR3m3Ov"
   },
   "outputs": [],
   "source": [
    "def mu(data):\n",
    "    I = data != 0  # Indicator function which is zero for missing data\n",
    "    ME=I*data #calculate the rating\n",
    "    return (np.sum(ME)/np.sum(I))  # mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aD1IHzzYnJsU"
   },
   "outputs": [],
   "source": [
    "def residual_mean(data,w,b,mean_w,mean_b):\n",
    "  I = data != 0\n",
    "  mean_w_matric=mean_w.T.dot(np.array([[1]*data.shape[1]]))\n",
    "  mean_b_matric=np.array([[1]*data.shape[0]]).T.dot(mean_b)\n",
    "  mu_matric=mu(data)*np.dot(np.array([[1]*data.shape[0]]).T,np.array([[1]*data.shape[1]]))\n",
    "  ME = I * (data -mu_matric-mean_w_matric-mean_b_matric- np.dot(w.T, b))\n",
    "  return ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WLxKDuiInNqM"
   },
   "outputs": [],
   "source": [
    "def error_mean(data,w,b,mean_w,mean_b,lamb):\n",
    "    totalError=0\n",
    "    matric=w.T.dot(b)\n",
    "    mean_w_matric=mean_w.T.dot(np.array([[1]*data.shape[1]]))\n",
    "    mean_b_matric=np.array([[1]*data.shape[0]]).T.dot(mean_b)\n",
    "    mu_data=mu(data)\n",
    "    for i in range(0,data.shape[0]):\n",
    "        for j in range(0,data.shape[1]):\n",
    "            if data[i][j]!=0:\n",
    "                totalError+=(data[i][j]-mu_data-mean_w_matric[i][j]-mean_b_matric[i][j]-matric[i][j])**2\n",
    "    totalError+=lamb*(w.dot(w.T)+b.dot(b.T)+mean_w.dot(mean_w.T)+mean_b.dot(mean_b.T))\n",
    "    return totalError[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Do6FYqFinSrk"
   },
   "outputs": [],
   "source": [
    "def step_gradient_mean(w,b,mean_w,mean_b,data,learning_rate,lamb):\n",
    "    w_gradient=(residual_mean(data,w,b,mean_w,mean_b).dot(b.T).reshape(1,w.shape[1])-w*lamb)\n",
    "    b_gradient=(residual_mean(data,w,b,mean_w,mean_b).T.dot(w.T).reshape(1,b.shape[1])-b*lamb)\n",
    "    mean_w_gradient=(residual_mean(data,w,b,mean_w,mean_b).dot(np.array([[1]*data.shape[1]]).T).reshape(1,mean_w.shape[1])-mean_w*lamb)\n",
    "    mean_b_gradient=(residual_mean(data,w,b,mean_w,mean_b).T.dot(np.array([[1]*data.shape[0]]).T).reshape(1,mean_b.shape[1])-mean_b*lamb)\n",
    "    new_w=w+(w_gradient*learning_rate)\n",
    "    new_b=b+(b_gradient*learning_rate)\n",
    "    new_mean_w=mean_w+(mean_w_gradient*learning_rate)\n",
    "    new_mean_b=mean_b+(mean_b_gradient*learning_rate)\n",
    "    return [new_w,new_b,new_mean_w,new_mean_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UpTpQ_kCnWOE"
   },
   "outputs": [],
   "source": [
    "def rmse_mean(data, w, b,mean_w,mean_b):\n",
    "    mean_w_matric=mean_w.T.dot(np.array([[1]*data.shape[1]]))\n",
    "    mean_b_matric=np.array([[1]*data.shape[0]]).T.dot(mean_b)\n",
    "    mu_matric=mu(data)*np.dot(np.array([[1]*data.shape[0]]).T,np.array([[1]*data.shape[1]]))\n",
    "    I = data != 0  # Indicator function which is zero for missing data\n",
    "    ME = I * (data-mu_matric -mean_w_matric-mean_b_matric- np.dot(w.T, b))  # Errors between real and predicted ratings\n",
    "    MSE = ME**2  \n",
    "    return np.sqrt(np.sum(MSE)/np.sum(I)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RErQUgzJnZ6U"
   },
   "outputs": [],
   "source": [
    "def gradient_descent_runner_mean(data,starting_w,starting_b,starting_mean_w,starting_mean_b,learning_rate,lamb,max_iterations):\n",
    "    b=starting_b\n",
    "    w=starting_w\n",
    "    mean_w=starting_mean_w\n",
    "    mean_b=starting_mean_b\n",
    "    lasterror = 0\n",
    "    rmse_list=[]\n",
    "    for i in range(max_iterations):\n",
    "        w,b,mean_w,mean_b=step_gradient_mean(w,b,mean_w,mean_b,data,learning_rate,lamb)\n",
    "        rmse_list.append(rmse_mean(data, w, b,mean_w,mean_b))\n",
    "        print(\"The {}-th iteration rmse = {}\".format(i+1,rmse_mean(data, w, b,mean_w,mean_b)))\n",
    "        print(\"------------------------------\")\n",
    "        if np.abs(error_mean(data,w,b,mean_w,mean_b,lamb)-lasterror)>0.1:\n",
    "          lasterror=error_mean(data,w,b,mean_w,mean_b,lamb)\n",
    "        else:\n",
    "          break\n",
    "    return rmse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "rJwINLZ5ncK0",
    "outputId": "f474c694-4586-4a50-eb64-9a241e352e65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 1-th iteration rmse = 1.0954603507443303\n",
      "------------------------------\n",
      "The 2-th iteration rmse = 1.0727784690733126\n",
      "------------------------------\n",
      "The 3-th iteration rmse = 1.0552609488382696\n",
      "------------------------------\n",
      "The 4-th iteration rmse = 1.0413367155133255\n",
      "------------------------------\n",
      "The 5-th iteration rmse = 1.0300016405054941\n",
      "------------------------------\n",
      "The 6-th iteration rmse = 1.020590955945247\n",
      "------------------------------\n",
      "The 7-th iteration rmse = 1.0126490297902806\n",
      "------------------------------\n",
      "The 8-th iteration rmse = 1.0058534345501153\n",
      "------------------------------\n",
      "The 9-th iteration rmse = 0.9999694962741976\n",
      "------------------------------\n",
      "The 10-th iteration rmse = 0.9948222401485397\n",
      "------------------------------\n",
      "The 11-th iteration rmse = 0.9902785034805677\n",
      "------------------------------\n",
      "The 12-th iteration rmse = 0.9862351627212789\n",
      "------------------------------\n",
      "The 13-th iteration rmse = 0.9826111524724035\n",
      "------------------------------\n",
      "The 14-th iteration rmse = 0.9793419106505721\n",
      "------------------------------\n",
      "The 15-th iteration rmse = 0.9763754225359026\n",
      "------------------------------\n",
      "The 16-th iteration rmse = 0.9736693472599943\n",
      "------------------------------\n",
      "The 17-th iteration rmse = 0.9711888947228884\n",
      "------------------------------\n",
      "The 18-th iteration rmse = 0.968905233606874\n",
      "------------------------------\n",
      "The 19-th iteration rmse = 0.9667942820172104\n",
      "------------------------------\n",
      "The 20-th iteration rmse = 0.9648357780795954\n",
      "------------------------------\n",
      "The 21-th iteration rmse = 0.9630125581701815\n",
      "------------------------------\n",
      "The 22-th iteration rmse = 0.9613099910068427\n",
      "------------------------------\n",
      "The 23-th iteration rmse = 0.9597155300193003\n",
      "------------------------------\n",
      "The 24-th iteration rmse = 0.9582183563747289\n",
      "------------------------------\n",
      "The 25-th iteration rmse = 0.9568090921272759\n",
      "------------------------------\n",
      "The 26-th iteration rmse = 0.9554795680745221\n",
      "------------------------------\n",
      "The 27-th iteration rmse = 0.9542226346348731\n",
      "------------------------------\n",
      "The 28-th iteration rmse = 0.9530320068098157\n",
      "------------------------------\n",
      "The 29-th iteration rmse = 0.95190213634119\n",
      "------------------------------\n",
      "The 30-th iteration rmse = 0.9508281057099932\n",
      "------------------------------\n",
      "The 31-th iteration rmse = 0.9498055397863611\n",
      "------------------------------\n",
      "The 32-th iteration rmse = 0.9488305318280477\n",
      "------------------------------\n",
      "The 33-th iteration rmse = 0.9478995812072394\n",
      "------------------------------\n",
      "The 34-th iteration rmse = 0.947009540774127\n",
      "------------------------------\n",
      "The 35-th iteration rmse = 0.9461575721778319\n",
      "------------------------------\n",
      "The 36-th iteration rmse = 0.9453411077887058\n",
      "------------------------------\n",
      "The 37-th iteration rmse = 0.9445578181214919\n",
      "------------------------------\n",
      "The 38-th iteration rmse = 0.9438055838616456\n",
      "------------------------------\n",
      "The 39-th iteration rmse = 0.9430824717591951\n",
      "------------------------------\n",
      "The 40-th iteration rmse = 0.9423867137845692\n",
      "------------------------------\n",
      "The 41-th iteration rmse = 0.941716689045799\n",
      "------------------------------\n",
      "The 42-th iteration rmse = 0.9410709080515908\n",
      "------------------------------\n",
      "The 43-th iteration rmse = 0.940447998974073\n",
      "------------------------------\n",
      "The 44-th iteration rmse = 0.9398466956216797\n",
      "------------------------------\n",
      "The 45-th iteration rmse = 0.9392658268791719\n",
      "------------------------------\n",
      "The 46-th iteration rmse = 0.9387043074101866\n",
      "------------------------------\n",
      "The 47-th iteration rmse = 0.9381611294494006\n",
      "------------------------------\n",
      "The 48-th iteration rmse = 0.9376353555377985\n",
      "------------------------------\n",
      "The 49-th iteration rmse = 0.9371261120764747\n",
      "------------------------------\n",
      "The 50-th iteration rmse = 0.9366325835927471\n",
      "------------------------------\n",
      "The 51-th iteration rmse = 0.9361540076277832\n",
      "------------------------------\n",
      "The 52-th iteration rmse = 0.9356896701678622\n",
      "------------------------------\n",
      "The 53-th iteration rmse = 0.9352389015523332\n",
      "------------------------------\n",
      "The 54-th iteration rmse = 0.9348010728005678\n",
      "------------------------------\n",
      "The 55-th iteration rmse = 0.9343755923080471\n",
      "------------------------------\n",
      "The 56-th iteration rmse = 0.9339619028683899\n",
      "------------------------------\n",
      "The 57-th iteration rmse = 0.9335594789838184\n",
      "------------------------------\n",
      "The 58-th iteration rmse = 0.9331678244314211\n",
      "------------------------------\n",
      "The 59-th iteration rmse = 0.932786470056742\n",
      "------------------------------\n",
      "The 60-th iteration rmse = 0.932414971769797\n",
      "------------------------------\n",
      "The 61-th iteration rmse = 0.9320529087217247\n",
      "------------------------------\n",
      "The 62-th iteration rmse = 0.9316998816429124\n",
      "------------------------------\n",
      "The 63-th iteration rmse = 0.931355511325761\n",
      "------------------------------\n",
      "The 64-th iteration rmse = 0.9310194372372544\n",
      "------------------------------\n",
      "The 65-th iteration rmse = 0.9306913162482011\n",
      "------------------------------\n",
      "The 66-th iteration rmse = 0.9303708214675707\n",
      "------------------------------\n",
      "The 67-th iteration rmse = 0.930057641171631\n",
      "------------------------------\n",
      "The 68-th iteration rmse = 0.9297514778187547\n",
      "------------------------------\n",
      "The 69-th iteration rmse = 0.9294520471417832\n",
      "------------------------------\n",
      "The 70-th iteration rmse = 0.9291590773107031\n",
      "------------------------------\n",
      "The 71-th iteration rmse = 0.9288723081591768\n",
      "------------------------------\n",
      "The 72-th iteration rmse = 0.928591490469162\n",
      "------------------------------\n",
      "The 73-th iteration rmse = 0.928316385308444\n",
      "------------------------------\n",
      "The 74-th iteration rmse = 0.9280467634164464\n",
      "------------------------------\n",
      "The 75-th iteration rmse = 0.9277824046341698\n",
      "------------------------------\n",
      "The 76-th iteration rmse = 0.9275230973745021\n",
      "------------------------------\n",
      "The 77-th iteration rmse = 0.9272686381295416\n",
      "------------------------------\n",
      "The 78-th iteration rmse = 0.927018831011893\n",
      "------------------------------\n",
      "The 79-th iteration rmse = 0.9267734873271957\n",
      "------------------------------\n",
      "The 80-th iteration rmse = 0.9265324251753986\n",
      "------------------------------\n",
      "The 81-th iteration rmse = 0.9262954690785529\n",
      "------------------------------\n",
      "The 82-th iteration rmse = 0.9260624496330726\n",
      "------------------------------\n",
      "The 83-th iteration rmse = 0.9258332031846376\n",
      "------------------------------\n",
      "The 84-th iteration rmse = 0.9256075715240542\n",
      "------------------------------\n",
      "The 85-th iteration rmse = 0.9253854016025543\n",
      "------------------------------\n",
      "The 86-th iteration rmse = 0.9251665452651572\n",
      "------------------------------\n",
      "The 87-th iteration rmse = 0.9249508590008224\n",
      "------------------------------\n",
      "The 88-th iteration rmse = 0.9247382037082555\n",
      "------------------------------\n",
      "The 89-th iteration rmse = 0.9245284444763139\n",
      "------------------------------\n",
      "The 90-th iteration rmse = 0.92432145037806\n",
      "------------------------------\n",
      "The 91-th iteration rmse = 0.9241170942775843\n",
      "------------------------------\n",
      "The 92-th iteration rmse = 0.923915252648803\n",
      "------------------------------\n",
      "The 93-th iteration rmse = 0.9237158054055027\n",
      "------------------------------\n",
      "The 94-th iteration rmse = 0.9235186357419541\n",
      "------------------------------\n",
      "The 95-th iteration rmse = 0.9233236299834886\n",
      "------------------------------\n",
      "The 96-th iteration rmse = 0.9231306774464813\n",
      "------------------------------\n",
      "The 97-th iteration rmse = 0.9229396703072079\n",
      "------------------------------\n",
      "The 98-th iteration rmse = 0.9227505034791268\n",
      "------------------------------\n",
      "The 99-th iteration rmse = 0.9225630744981265\n",
      "------------------------------\n",
      "The 100-th iteration rmse = 0.9223772834153606\n",
      "------------------------------\n",
      "The 101-th iteration rmse = 0.922193032697291\n",
      "------------------------------\n",
      "The 102-th iteration rmse = 0.922010227132604\n",
      "------------------------------\n",
      "The 103-th iteration rmse = 0.9218287737456862\n",
      "------------------------------\n",
      "The 104-th iteration rmse = 0.9216485817163806\n",
      "------------------------------\n",
      "The 105-th iteration rmse = 0.9214695623057433\n",
      "------------------------------\n",
      "The 106-th iteration rmse = 0.9212916287875688\n",
      "------------------------------\n",
      "The 107-th iteration rmse = 0.9211146963854451\n",
      "------------------------------\n",
      "The 108-th iteration rmse = 0.9209386822151354\n",
      "------------------------------\n",
      "The 109-th iteration rmse = 0.9207635052320822\n",
      "------------------------------\n",
      "The 110-th iteration rmse = 0.9205890861838516\n",
      "------------------------------\n",
      "The 111-th iteration rmse = 0.9204153475673497\n",
      "------------------------------\n",
      "The 112-th iteration rmse = 0.920242213590637\n",
      "------------------------------\n",
      "The 113-th iteration rmse = 0.9200696101391984\n",
      "------------------------------\n",
      "The 114-th iteration rmse = 0.9198974647465186\n",
      "------------------------------\n",
      "The 115-th iteration rmse = 0.9197257065688133\n",
      "------------------------------\n",
      "The 116-th iteration rmse = 0.919554266363799\n",
      "------------------------------\n",
      "The 117-th iteration rmse = 0.9193830764733548\n",
      "------------------------------\n",
      "The 118-th iteration rmse = 0.9192120708099583\n",
      "------------------------------\n",
      "The 119-th iteration rmse = 0.9190411848467621\n",
      "------------------------------\n",
      "The 120-th iteration rmse = 0.918870355611197\n",
      "------------------------------\n",
      "The 121-th iteration rmse = 0.9186995216819706\n",
      "------------------------------\n",
      "The 122-th iteration rmse = 0.9185286231893361\n",
      "------------------------------\n",
      "The 123-th iteration rmse = 0.9183576018185112\n",
      "------------------------------\n",
      "The 124-th iteration rmse = 0.9181864008161167\n",
      "------------------------------\n",
      "The 125-th iteration rmse = 0.9180149649995009\n",
      "------------------------------\n",
      "The 126-th iteration rmse = 0.9178432407688203\n",
      "------------------------------\n",
      "The 127-th iteration rmse = 0.9176711761217352\n",
      "------------------------------\n",
      "The 128-th iteration rmse = 0.9174987206705754\n",
      "------------------------------\n",
      "The 129-th iteration rmse = 0.9173258256618287\n",
      "------------------------------\n",
      "The 130-th iteration rmse = 0.9171524439977987\n",
      "------------------------------\n",
      "The 131-th iteration rmse = 0.9169785302602596\n",
      "------------------------------\n",
      "The 132-th iteration rmse = 0.9168040407359569\n",
      "------------------------------\n",
      "The 133-th iteration rmse = 0.916628933443758\n",
      "------------------------------\n",
      "The 134-th iteration rmse = 0.9164531681632839\n",
      "------------------------------\n",
      "The 135-th iteration rmse = 0.9162767064648197\n",
      "------------------------------\n",
      "The 136-th iteration rmse = 0.9160995117403105\n",
      "------------------------------\n",
      "The 137-th iteration rmse = 0.9159215492352306\n",
      "------------------------------\n",
      "The 138-th iteration rmse = 0.9157427860811098\n",
      "------------------------------\n",
      "The 139-th iteration rmse = 0.9155631913284976\n",
      "------------------------------\n",
      "The 140-th iteration rmse = 0.9153827359801241\n",
      "------------------------------\n",
      "The 141-th iteration rmse = 0.9152013930240234\n",
      "------------------------------\n",
      "The 142-th iteration rmse = 0.9150191374663758\n",
      "------------------------------\n",
      "The 143-th iteration rmse = 0.9148359463638078\n",
      "------------------------------\n",
      "The 144-th iteration rmse = 0.9146517988548963\n",
      "------------------------------\n",
      "The 145-th iteration rmse = 0.9144666761906116\n",
      "------------------------------\n",
      "The 146-th iteration rmse = 0.9142805617634271\n",
      "------------------------------\n",
      "The 147-th iteration rmse = 0.9140934411348305\n",
      "------------------------------\n",
      "The 148-th iteration rmse = 0.9139053020609558\n",
      "------------------------------\n",
      "The 149-th iteration rmse = 0.9137161345160626\n",
      "------------------------------\n",
      "The 150-th iteration rmse = 0.9135259307135912\n",
      "------------------------------\n",
      "The 151-th iteration rmse = 0.9133346851245175\n",
      "------------------------------\n",
      "The 152-th iteration rmse = 0.9131423944927363\n",
      "------------------------------\n",
      "The 153-th iteration rmse = 0.9129490578472139\n",
      "------------------------------\n",
      "The 154-th iteration rmse = 0.9127546765106449\n",
      "------------------------------\n",
      "The 155-th iteration rmse = 0.9125592541043686\n",
      "------------------------------\n",
      "The 156-th iteration rmse = 0.912362796549307\n",
      "------------------------------\n",
      "The 157-th iteration rmse = 0.9121653120626873\n",
      "------------------------------\n",
      "The 158-th iteration rmse = 0.9119668111503481\n",
      "------------------------------\n",
      "The 159-th iteration rmse = 0.9117673065944251\n",
      "------------------------------\n",
      "The 160-th iteration rmse = 0.9115668134362364\n",
      "------------------------------\n",
      "The 161-th iteration rmse = 0.9113653489542124\n",
      "------------------------------\n",
      "The 162-th iteration rmse = 0.9111629326367324\n",
      "------------------------------\n",
      "The 163-th iteration rmse = 0.91095958614974\n",
      "------------------------------\n",
      "The 164-th iteration rmse = 0.9107553332990781\n",
      "------------------------------\n",
      "The 165-th iteration rmse = 0.9105501999874402\n",
      "------------------------------\n",
      "The 166-th iteration rmse = 0.9103442141659458\n",
      "------------------------------\n",
      "The 167-th iteration rmse = 0.9101374057802999\n",
      "------------------------------\n",
      "The 168-th iteration rmse = 0.9099298067115855\n",
      "------------------------------\n",
      "The 169-th iteration rmse = 0.9097214507117335\n",
      "------------------------------\n",
      "The 170-th iteration rmse = 0.9095123733337631\n",
      "------------------------------\n",
      "The 171-th iteration rmse = 0.9093026118569159\n",
      "------------------------------\n",
      "The 172-th iteration rmse = 0.9090922052068325\n",
      "------------------------------\n",
      "The 173-th iteration rmse = 0.9088811938709666\n",
      "------------------------------\n",
      "The 174-th iteration rmse = 0.9086696198094416\n",
      "------------------------------\n",
      "The 175-th iteration rmse = 0.9084575263616199\n",
      "------------------------------\n",
      "The 176-th iteration rmse = 0.9082449581486446\n",
      "------------------------------\n",
      "The 177-th iteration rmse = 0.9080319609722768\n",
      "------------------------------\n",
      "The 178-th iteration rmse = 0.9078185817103654\n",
      "------------------------------\n",
      "The 179-th iteration rmse = 0.9076048682093059\n",
      "------------------------------\n",
      "The 180-th iteration rmse = 0.9073908691738808\n",
      "------------------------------\n",
      "The 181-th iteration rmse = 0.9071766340548939\n",
      "------------------------------\n",
      "The 182-th iteration rmse = 0.9069622129350131\n",
      "------------------------------\n",
      "The 183-th iteration rmse = 0.9067476564132789\n",
      "------------------------------\n",
      "The 184-th iteration rmse = 0.9065330154887298\n",
      "------------------------------\n",
      "The 185-th iteration rmse = 0.9063183414436047\n",
      "------------------------------\n",
      "The 186-th iteration rmse = 0.9061036857266002\n",
      "------------------------------\n",
      "The 187-th iteration rmse = 0.9058890998366642\n",
      "------------------------------\n",
      "The 188-th iteration rmse = 0.9056746352077809\n",
      "------------------------------\n",
      "The 189-th iteration rmse = 0.9054603430952405\n",
      "------------------------------\n",
      "The 190-th iteration rmse = 0.9052462744638392\n",
      "------------------------------\n",
      "The 191-th iteration rmse = 0.9050324798784689\n",
      "------------------------------\n",
      "The 192-th iteration rmse = 0.9048190093975333\n",
      "------------------------------\n",
      "The 193-th iteration rmse = 0.9046059124696071\n",
      "------------------------------\n",
      "The 194-th iteration rmse = 0.9043932378337415\n",
      "------------------------------\n",
      "The 195-th iteration rmse = 0.9041810334237844\n",
      "------------------------------\n",
      "The 196-th iteration rmse = 0.9039693462770723\n",
      "------------------------------\n",
      "The 197-th iteration rmse = 0.903758222447807\n",
      "------------------------------\n",
      "The 198-th iteration rmse = 0.9035477069254091\n",
      "------------------------------\n",
      "The 199-th iteration rmse = 0.9033378435581089\n",
      "------------------------------\n",
      "The 200-th iteration rmse = 0.9031286749819873\n",
      "------------------------------\n",
      "The 201-th iteration rmse = 0.9029202425556655\n",
      "------------------------------\n",
      "The 202-th iteration rmse = 0.9027125863007885\n",
      "------------------------------\n",
      "The 203-th iteration rmse = 0.9025057448484175\n",
      "------------------------------\n",
      "The 204-th iteration rmse = 0.9022997553914123\n",
      "------------------------------\n",
      "The 205-th iteration rmse = 0.9020946536428455\n",
      "------------------------------\n",
      "The 206-th iteration rmse = 0.9018904738004472\n",
      "------------------------------\n",
      "The 207-th iteration rmse = 0.9016872485170678\n",
      "------------------------------\n",
      "The 208-th iteration rmse = 0.9014850088770789\n",
      "------------------------------\n",
      "The 209-th iteration rmse = 0.9012837843786289\n",
      "------------------------------\n",
      "The 210-th iteration rmse = 0.9010836029216227\n",
      "------------------------------\n",
      "The 211-th iteration rmse = 0.9008844908012783\n",
      "------------------------------\n",
      "The 212-th iteration rmse = 0.9006864727070661\n",
      "------------------------------\n",
      "The 213-th iteration rmse = 0.9004895717268488\n",
      "------------------------------\n",
      "The 214-th iteration rmse = 0.9002938093559697\n",
      "------------------------------\n",
      "The 215-th iteration rmse = 0.9000992055110628\n",
      "------------------------------\n",
      "The 216-th iteration rmse = 0.899905778548313\n",
      "------------------------------\n",
      "The 217-th iteration rmse = 0.8997135452858966\n",
      "------------------------------\n",
      "The 218-th iteration rmse = 0.8995225210303053\n",
      "------------------------------\n",
      "The 219-th iteration rmse = 0.8993327196062639\n",
      "------------------------------\n",
      "The 220-th iteration rmse = 0.8991441533899375\n",
      "------------------------------\n",
      "The 221-th iteration rmse = 0.8989568333451191\n",
      "------------------------------\n",
      "The 222-th iteration rmse = 0.8987707690620937\n",
      "------------------------------\n",
      "The 223-th iteration rmse = 0.8985859687988642\n",
      "------------------------------\n",
      "The 224-th iteration rmse = 0.8984024395244486\n",
      "------------------------------\n",
      "The 225-th iteration rmse = 0.8982201869639307\n",
      "------------------------------\n",
      "The 226-th iteration rmse = 0.8980392156449916\n",
      "------------------------------\n",
      "The 227-th iteration rmse = 0.897859528945624\n",
      "------------------------------\n",
      "The 228-th iteration rmse = 0.8976811291427645\n",
      "------------------------------\n",
      "The 229-th iteration rmse = 0.8975040174615803\n",
      "------------------------------\n",
      "The 230-th iteration rmse = 0.8973281941251539\n",
      "------------------------------\n",
      "The 231-th iteration rmse = 0.8971536584043432\n",
      "------------------------------\n",
      "The 232-th iteration rmse = 0.8969804086675822\n",
      "------------------------------\n",
      "The 233-th iteration rmse = 0.8968084424304243\n",
      "------------------------------\n",
      "The 234-th iteration rmse = 0.8966377564046307\n",
      "------------------------------\n",
      "The 235-th iteration rmse = 0.8964683465466327\n",
      "------------------------------\n",
      "The 236-th iteration rmse = 0.8963002081052004\n",
      "------------------------------\n",
      "The 237-th iteration rmse = 0.8961333356681853\n",
      "------------------------------\n",
      "The 238-th iteration rmse = 0.8959677232081883\n",
      "------------------------------\n",
      "The 239-th iteration rmse = 0.8958033641270575\n",
      "------------------------------\n",
      "The 240-th iteration rmse = 0.8956402512991062\n",
      "------------------------------\n",
      "The 241-th iteration rmse = 0.8954783771129637\n",
      "------------------------------\n",
      "The 242-th iteration rmse = 0.8953177335119983\n",
      "------------------------------\n",
      "The 243-th iteration rmse = 0.8951583120332384\n",
      "------------------------------\n",
      "The 244-th iteration rmse = 0.8950001038447604\n",
      "------------------------------\n",
      "The 245-th iteration rmse = 0.8948430997814998\n",
      "------------------------------\n",
      "The 246-th iteration rmse = 0.8946872903794673\n",
      "------------------------------\n",
      "The 247-th iteration rmse = 0.8945326659083531\n",
      "------------------------------\n",
      "The 248-th iteration rmse = 0.8943792164025164\n",
      "------------------------------\n",
      "The 249-th iteration rmse = 0.8942269316903713\n",
      "------------------------------\n",
      "The 250-th iteration rmse = 0.8940758014221731\n",
      "------------------------------\n",
      "The 251-th iteration rmse = 0.8939258150962284\n",
      "------------------------------\n",
      "The 252-th iteration rmse = 0.8937769620835595\n",
      "------------------------------\n",
      "The 253-th iteration rmse = 0.8936292316510533\n",
      "------------------------------\n",
      "The 254-th iteration rmse = 0.8934826129831207\n",
      "------------------------------\n",
      "The 255-th iteration rmse = 0.8933370952019318\n",
      "------------------------------\n",
      "The 256-th iteration rmse = 0.8931926673862437\n",
      "------------------------------\n",
      "The 257-th iteration rmse = 0.8930493185888909\n",
      "------------------------------\n",
      "The 258-th iteration rmse = 0.8929070378529735\n",
      "------------------------------\n",
      "The 259-th iteration rmse = 0.892765814226806\n",
      "------------------------------\n",
      "The 260-th iteration rmse = 0.8926256367776702\n",
      "------------------------------\n",
      "The 261-th iteration rmse = 0.8924864946044337\n",
      "------------------------------\n",
      "The 262-th iteration rmse = 0.8923483768490879\n",
      "------------------------------\n",
      "The 263-th iteration rmse = 0.8922112727072522\n",
      "------------------------------\n",
      "The 264-th iteration rmse = 0.8920751714377118\n",
      "------------------------------\n",
      "The 265-th iteration rmse = 0.8919400623710304\n",
      "------------------------------\n",
      "The 266-th iteration rmse = 0.8918059349173008\n",
      "------------------------------\n",
      "The 267-th iteration rmse = 0.8916727785730783\n",
      "------------------------------\n",
      "The 268-th iteration rmse = 0.8915405829275536\n",
      "------------------------------\n",
      "The 269-th iteration rmse = 0.8914093376680063\n",
      "------------------------------\n",
      "The 270-th iteration rmse = 0.8912790325846005\n",
      "------------------------------\n",
      "The 271-th iteration rmse = 0.8911496575745501\n",
      "------------------------------\n",
      "The 272-th iteration rmse = 0.8910212026457158\n",
      "------------------------------\n",
      "The 273-th iteration rmse = 0.8908936579196667\n",
      "------------------------------\n",
      "The 274-th iteration rmse = 0.8907670136342477\n",
      "------------------------------\n",
      "The 275-th iteration rmse = 0.8906412601456927\n",
      "------------------------------\n",
      "The 276-th iteration rmse = 0.8905163879303242\n",
      "------------------------------\n",
      "The 277-th iteration rmse = 0.8903923875858648\n",
      "------------------------------\n",
      "The 278-th iteration rmse = 0.8902692498324037\n",
      "------------------------------\n",
      "The 279-th iteration rmse = 0.890146965513042\n",
      "------------------------------\n",
      "The 280-th iteration rmse = 0.8900255255942492\n",
      "------------------------------\n",
      "The 281-th iteration rmse = 0.889904921165959\n",
      "------------------------------\n",
      "The 282-th iteration rmse = 0.8897851434414221\n",
      "------------------------------\n",
      "The 283-th iteration rmse = 0.8896661837568584\n",
      "------------------------------\n",
      "The 284-th iteration rmse = 0.8895480335709032\n",
      "------------------------------\n",
      "The 285-th iteration rmse = 0.8894306844638973\n",
      "------------------------------\n",
      "The 286-th iteration rmse = 0.8893141281370157\n",
      "------------------------------\n",
      "The 287-th iteration rmse = 0.8891983564112695\n",
      "------------------------------\n",
      "The 288-th iteration rmse = 0.8890833612263868\n",
      "------------------------------\n",
      "The 289-th iteration rmse = 0.8889691346395923\n",
      "------------------------------\n",
      "The 290-th iteration rmse = 0.8888556688243009\n",
      "------------------------------\n",
      "The 291-th iteration rmse = 0.8887429560687293\n",
      "------------------------------\n",
      "The 292-th iteration rmse = 0.8886309887744508\n",
      "------------------------------\n",
      "The 293-th iteration rmse = 0.8885197594548871\n",
      "------------------------------\n",
      "The 294-th iteration rmse = 0.8884092607337657\n",
      "------------------------------\n",
      "The 295-th iteration rmse = 0.8882994853435285\n",
      "------------------------------\n",
      "The 296-th iteration rmse = 0.8881904261237251\n",
      "------------------------------\n",
      "The 297-th iteration rmse = 0.888082076019374\n",
      "------------------------------\n",
      "The 298-th iteration rmse = 0.8879744280793129\n",
      "------------------------------\n",
      "The 299-th iteration rmse = 0.8878674754545411\n",
      "------------------------------\n",
      "The 300-th iteration rmse = 0.8877612113965522\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.0004\n",
    "lamb=0.01\n",
    "w=np.array([[-0.1]*data.shape[0]])\n",
    "b=np.array([[0.2]*data.shape[1]])\n",
    "mean_w=np.array([[-0.1]*data.shape[0]])\n",
    "mean_b=np.array([[0.1]*data.shape[1]])\n",
    "max_iterations=300\n",
    "root_mean_square_error_mean=gradient_descent_runner_mean(data,w,b,mean_w,mean_b,learning_rate,lamb,max_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fwaX_Y1HoKZ1"
   },
   "source": [
    "## **With Min-batch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hk4naPuuoOvI"
   },
   "outputs": [],
   "source": [
    "def mu(data):\n",
    "    I = data != 0  # Indicator function which is zero for missing data\n",
    "    ME=I*data #calculate the rating\n",
    "    return (np.sum(ME)/np.sum(I))  # mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "63aN3i7sps7z"
   },
   "outputs": [],
   "source": [
    "def minbatch_partial_residual_mean(data,i,minbatch,w,b,mean_w,mean_b):\n",
    "  random.seed(10)\n",
    "  group_index=[[row[l],column[l]] for l in range(len(row))]\n",
    "  v=0\n",
    "  group=[]\n",
    "  while v < row.shape[0]:\n",
    "    group.append(group_index[v:v+minbatch])\n",
    "    v+=minbatch\n",
    "  group=np.array(group)\n",
    "  ##group[k][l][m]=> k-th group l-th data m=0 =>row m=1 =>column\n",
    "\n",
    "  zero=np.zeros(data.shape)\n",
    "  data_zero=np.zeros(data.shape)\n",
    "  for k in range(group[i].shape[0]):\n",
    "    zero[group[i][k][0]][group[i][k][1]]=1\n",
    "    data_zero[group[i][k][0]][group[i][k][1]]=data[group[i][k][0]][group[i][k][1]]\n",
    "\n",
    "  mean_w_matric=mean_w.T.dot(np.array([[1]*data.shape[1]]))\n",
    "  mean_b_matric=np.array([[1]*data.shape[0]]).T.dot(mean_b)\n",
    "  mu_matric=mu(data)*np.dot(np.array([[1]*data.shape[0]]).T , np.array([[1]*data.shape[1]]))\n",
    "  minbatch_partial_residual = zero * (data_zero -mu_matric-mean_w_matric-mean_b_matric- np.dot(w.T, b))\n",
    "  return minbatch_partial_residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6TnK9KY7rD35"
   },
   "outputs": [],
   "source": [
    "def minbatch_step_gradient_mean(w,b,mean_w,mean_b,data,i,minbatch,learning_rate,lamb):\n",
    "    w_gradient=(minbatch_partial_residual_mean(data,i,minbatch,w,b,mean_w,mean_b).dot(b.T).T-w*lamb)\n",
    "    b_gradient=(minbatch_partial_residual_mean(data,i,minbatch,w,b,mean_w,mean_b).T.dot(w.T).T-b*lamb)\n",
    "    mean_w_gradient=(minbatch_partial_residual_mean(data,i,minbatch,w,b,mean_w,mean_b).dot(np.array([[1]*data.shape[1]]).T).T-mean_w*lamb)\n",
    "    mean_b_gradient=(minbatch_partial_residual_mean(data,i,minbatch,w,b,mean_w,mean_b).T.dot(np.array([[1]*data.shape[0]]).T).T-mean_b*lamb)\n",
    "    new_w=w+(w_gradient*learning_rate)\n",
    "    new_b=b+(b_gradient*learning_rate)\n",
    "    new_mean_w=mean_w+(mean_w_gradient*learning_rate)\n",
    "    new_mean_b=mean_b+(mean_b_gradient*learning_rate)\n",
    "    return [new_w,new_b,new_mean_w,new_mean_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y9bzN_VWpySg"
   },
   "outputs": [],
   "source": [
    "def error_mean(data,w,b,mean_w,mean_b,lamb):\n",
    "    totalError=0\n",
    "    matric=w.T.dot(b)\n",
    "    mean_w_matric=mean_w.T.dot(np.array([[1]*data.shape[1]]))\n",
    "    mean_b_matric=np.array([[1]*data.shape[0]]).T.dot(mean_b)\n",
    "    mu_data=mu(data)\n",
    "    for i in range(0,data.shape[0]):\n",
    "        for j in range(0,data.shape[1]):\n",
    "            if data[i][j]!=0:\n",
    "                totalError+=(data[i][j]-mu_data-mean_w_matric[i][j]-mean_b_matric[i][j]-matric[i][j])**2\n",
    "    totalError+=lamb*(w.dot(w.T)+b.dot(b.T)+mean_w.dot(mean_w.T)+mean_b.dot(mean_b.T))\n",
    "    return totalError[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "10J__XWpwHlz"
   },
   "outputs": [],
   "source": [
    "def rmse_mean(data, w, b,mean_w,mean_b):\n",
    "    mean_w_matric=mean_w.T.dot(np.array([[1]*data.shape[1]]))\n",
    "    mean_b_matric=np.array([[1]*data.shape[0]]).T.dot(mean_b)\n",
    "    mu_matric=mu(data)*np.dot(np.array([[1]*data.shape[0]]).T,np.array([[1]*data.shape[1]]))\n",
    "    I = data != 0  # Indicator function which is zero for missing data\n",
    "    ME = I * (data-mu_matric -mean_w_matric-mean_b_matric- np.dot(w.T, b))  # Errors between real and predicted ratings\n",
    "    MSE = ME**2  \n",
    "    return np.sqrt(np.sum(MSE)/np.sum(I)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZxGWti97rmBH"
   },
   "outputs": [],
   "source": [
    "def minbatch_gradient_descent_runner_mean(data,starting_w,starting_b,starting_mean_w,starting_mean_b,minbatch,learning_rate,lamb,max_iterations):\n",
    "    b=starting_b\n",
    "    w=starting_w\n",
    "    mean_w=starting_mean_w\n",
    "    mean_b=starting_mean_b\n",
    "    lasterror = 0\n",
    "    rmse_list=[]\n",
    "\n",
    "    ##put data sample without replacement into group\n",
    "    random.seed(10)\n",
    "    group_index=[[row[l],column[l]] for l in range(len(row))]\n",
    "    v=0\n",
    "    group=[]\n",
    "    while v < row.shape[0]:\n",
    "      group.append(group_index[v:v+minbatch])\n",
    "      v+=minbatch\n",
    "    group=np.array(group)\n",
    "    ##group[k][l][m]=> k-th group l-th data m=0 =>row m=1 =>column\n",
    "    \n",
    "    for j in range(0,max_iterations):    \n",
    "      for i in range(0,group.shape[0]):\n",
    "        zero=np.zeros(data.shape)\n",
    "        w,b,mean_w,mean_b=minbatch_step_gradient_mean(w,b,mean_w,mean_b,data,i,minbatch,learning_rate,lamb)\n",
    "      rmse_list.append(rmse_mean(data, w, b,mean_w,mean_b))\n",
    "      print(\"The {}-th iteration rmse = {}\".format(j+1,rmse_mean(data, w, b,mean_w,mean_b)))\n",
    "      print(\"------------------------------\")\n",
    "      if np.abs(error_mean(data,w,b,mean_w,mean_b,lamb)-lasterror)>0.1:\n",
    "          lasterror=error_mean(data,w,b,mean_w,mean_b,lamb)\n",
    "      else:\n",
    "        break\n",
    "    return rmse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "XKaRpKYpsIbm",
    "outputId": "e05193de-8d03-4065-fd50-2841fd78306a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 1-th iteration rmse = 1.096035349994559\n",
      "------------------------------\n",
      "The 2-th iteration rmse = 1.0736575539657933\n",
      "------------------------------\n",
      "The 3-th iteration rmse = 1.056279062270942\n",
      "------------------------------\n",
      "The 4-th iteration rmse = 1.0423965872394305\n",
      "------------------------------\n",
      "The 5-th iteration rmse = 1.0310481829717755\n",
      "------------------------------\n",
      "The 6-th iteration rmse = 1.02159476370301\n",
      "------------------------------\n",
      "The 7-th iteration rmse = 1.0135960221154101\n",
      "------------------------------\n",
      "The 8-th iteration rmse = 1.006738468750487\n",
      "------------------------------\n",
      "The 9-th iteration rmse = 1.000792482726094\n",
      "------------------------------\n",
      "The 10-th iteration rmse = 0.9955858081623129\n",
      "------------------------------\n",
      "The 11-th iteration rmse = 0.9909866178984699\n",
      "------------------------------\n",
      "The 12-th iteration rmse = 0.9868923184581162\n",
      "------------------------------\n",
      "The 13-th iteration rmse = 0.9832219177722757\n",
      "------------------------------\n",
      "The 14-th iteration rmse = 0.9799106790818102\n",
      "------------------------------\n",
      "The 15-th iteration rmse = 0.9769062886738631\n",
      "------------------------------\n",
      "The 16-th iteration rmse = 0.9741660545940425\n",
      "------------------------------\n",
      "The 17-th iteration rmse = 0.9716548247767581\n",
      "------------------------------\n",
      "The 18-th iteration rmse = 0.9693434176842036\n",
      "------------------------------\n",
      "The 19-th iteration rmse = 0.9672074245161766\n",
      "------------------------------\n",
      "The 20-th iteration rmse = 0.9652262848807143\n",
      "------------------------------\n",
      "The 21-th iteration rmse = 0.9633825663568272\n",
      "------------------------------\n",
      "The 22-th iteration rmse = 0.9616613978376359\n",
      "------------------------------\n",
      "The 23-th iteration rmse = 0.960050020065296\n",
      "------------------------------\n",
      "The 24-th iteration rmse = 0.9585374263234202\n",
      "------------------------------\n",
      "The 25-th iteration rmse = 0.9571140730985115\n",
      "------------------------------\n",
      "The 26-th iteration rmse = 0.9557716454873294\n",
      "------------------------------\n",
      "The 27-th iteration rmse = 0.9545028657678781\n",
      "------------------------------\n",
      "The 28-th iteration rmse = 0.9533013362475702\n",
      "------------------------------\n",
      "The 29-th iteration rmse = 0.9521614095164787\n",
      "------------------------------\n",
      "The 30-th iteration rmse = 0.9510780807515766\n",
      "------------------------------\n",
      "The 31-th iteration rmse = 0.9500468978709311\n",
      "------------------------------\n",
      "The 32-th iteration rmse = 0.9490638862194603\n",
      "------------------------------\n",
      "The 33-th iteration rmse = 0.9481254851483485\n",
      "------------------------------\n",
      "The 34-th iteration rmse = 0.9472284943785606\n",
      "------------------------------\n",
      "The 35-th iteration rmse = 0.946370028451763\n",
      "------------------------------\n",
      "The 36-th iteration rmse = 0.9455474778966977\n",
      "------------------------------\n",
      "The 37-th iteration rmse = 0.9447584759959446\n",
      "------------------------------\n",
      "The 38-th iteration rmse = 0.9440008702424301\n",
      "------------------------------\n",
      "The 39-th iteration rmse = 0.9432726977385546\n",
      "------------------------------\n",
      "The 40-th iteration rmse = 0.9425721639223281\n",
      "------------------------------\n",
      "The 41-th iteration rmse = 0.9418976241111136\n",
      "------------------------------\n",
      "The 42-th iteration rmse = 0.9412475674398718\n",
      "------------------------------\n",
      "The 43-th iteration rmse = 0.9406206028410721\n",
      "------------------------------\n",
      "The 44-th iteration rmse = 0.9400154467710388\n",
      "------------------------------\n",
      "The 45-th iteration rmse = 0.9394309124348121\n",
      "------------------------------\n",
      "The 46-th iteration rmse = 0.9388659003006414\n",
      "------------------------------\n",
      "The 47-th iteration rmse = 0.9383193897275779\n",
      "------------------------------\n",
      "The 48-th iteration rmse = 0.9377904315564828\n",
      "------------------------------\n",
      "The 49-th iteration rmse = 0.9372781415371815\n",
      "------------------------------\n",
      "The 50-th iteration rmse = 0.9367816944832184\n",
      "------------------------------\n",
      "The 51-th iteration rmse = 0.9363003190613977\n",
      "------------------------------\n",
      "The 52-th iteration rmse = 0.9358332931365078\n",
      "------------------------------\n",
      "The 53-th iteration rmse = 0.9353799396028012\n",
      "------------------------------\n",
      "The 54-th iteration rmse = 0.9349396226432428\n",
      "------------------------------\n",
      "The 55-th iteration rmse = 0.934511744365561\n",
      "------------------------------\n",
      "The 56-th iteration rmse = 0.9340957417709408\n",
      "------------------------------\n",
      "The 57-th iteration rmse = 0.9336910840170357\n",
      "------------------------------\n",
      "The 58-th iteration rmse = 0.9332972699419309\n",
      "------------------------------\n",
      "The 59-th iteration rmse = 0.9329138258199723\n",
      "------------------------------\n",
      "The 60-th iteration rmse = 0.932540303324015\n",
      "------------------------------\n",
      "The 61-th iteration rmse = 0.9321762776718266\n",
      "------------------------------\n",
      "The 62-th iteration rmse = 0.9318213459370829\n",
      "------------------------------\n",
      "The 63-th iteration rmse = 0.9314751255077591\n",
      "------------------------------\n",
      "The 64-th iteration rmse = 0.9311372526767618\n",
      "------------------------------\n",
      "The 65-th iteration rmse = 0.9308073813514115\n",
      "------------------------------\n",
      "The 66-th iteration rmse = 0.9304851818699482\n",
      "------------------------------\n",
      "The 67-th iteration rmse = 0.9301703399145537\n",
      "------------------------------\n",
      "The 68-th iteration rmse = 0.9298625555115881\n",
      "------------------------------\n",
      "The 69-th iteration rmse = 0.9295615421107485\n",
      "------------------------------\n",
      "The 70-th iteration rmse = 0.9292670257357737\n",
      "------------------------------\n",
      "The 71-th iteration rmse = 0.9289787442001094\n",
      "------------------------------\n",
      "The 72-th iteration rmse = 0.9286964463816472\n",
      "------------------------------\n",
      "The 73-th iteration rmse = 0.9284198915512742\n",
      "------------------------------\n",
      "The 74-th iteration rmse = 0.9281488487505039\n",
      "------------------------------\n",
      "The 75-th iteration rmse = 0.9278830962139583\n",
      "------------------------------\n",
      "The 76-th iteration rmse = 0.9276224208328813\n",
      "------------------------------\n",
      "The 77-th iteration rmse = 0.9273666176562593\n",
      "------------------------------\n",
      "The 78-th iteration rmse = 0.9271154894264556\n",
      "------------------------------\n",
      "The 79-th iteration rmse = 0.9268688461465584\n",
      "------------------------------\n",
      "The 80-th iteration rmse = 0.9266265046769341\n",
      "------------------------------\n",
      "The 81-th iteration rmse = 0.9263882883586958\n",
      "------------------------------\n",
      "The 82-th iteration rmse = 0.9261540266620132\n",
      "------------------------------\n",
      "The 83-th iteration rmse = 0.9259235548574056\n",
      "------------------------------\n",
      "The 84-th iteration rmse = 0.9256967137082993\n",
      "------------------------------\n",
      "The 85-th iteration rmse = 0.9254733491833139\n",
      "------------------------------\n",
      "The 86-th iteration rmse = 0.9252533121868655\n",
      "------------------------------\n",
      "The 87-th iteration rmse = 0.9250364583068097\n",
      "------------------------------\n",
      "The 88-th iteration rmse = 0.9248226475779555\n",
      "------------------------------\n",
      "The 89-th iteration rmse = 0.9246117442603828\n",
      "------------------------------\n",
      "The 90-th iteration rmse = 0.9244036166315989\n",
      "------------------------------\n",
      "The 91-th iteration rmse = 0.924198136791642\n",
      "------------------------------\n",
      "The 92-th iteration rmse = 0.9239951804803211\n",
      "------------------------------\n",
      "The 93-th iteration rmse = 0.9237946269058505\n",
      "------------------------------\n",
      "The 94-th iteration rmse = 0.9235963585842021\n",
      "------------------------------\n",
      "The 95-th iteration rmse = 0.9234002611885475\n",
      "------------------------------\n",
      "The 96-th iteration rmse = 0.9232062234082281\n",
      "------------------------------\n",
      "The 97-th iteration rmse = 0.9230141368167212\n",
      "------------------------------\n",
      "The 98-th iteration rmse = 0.9228238957481284\n",
      "------------------------------\n",
      "The 99-th iteration rmse = 0.922635397181742\n",
      "------------------------------\n",
      "The 100-th iteration rmse = 0.9224485406342854\n",
      "------------------------------\n",
      "The 101-th iteration rmse = 0.9222632280594554\n",
      "------------------------------\n",
      "The 102-th iteration rmse = 0.9220793637544198\n",
      "------------------------------\n",
      "The 103-th iteration rmse = 0.9218968542729549\n",
      "------------------------------\n",
      "The 104-th iteration rmse = 0.9217156083449366\n",
      "------------------------------\n",
      "The 105-th iteration rmse = 0.921535536801903\n",
      "------------------------------\n",
      "The 106-th iteration rmse = 0.9213565525084504\n",
      "------------------------------\n",
      "The 107-th iteration rmse = 0.9211785702992233\n",
      "------------------------------\n",
      "The 108-th iteration rmse = 0.9210015069212848\n",
      "------------------------------\n",
      "The 109-th iteration rmse = 0.9208252809816685\n",
      "------------------------------\n",
      "The 110-th iteration rmse = 0.9206498128999188\n",
      "------------------------------\n",
      "The 111-th iteration rmse = 0.9204750248654475\n",
      "------------------------------\n",
      "The 112-th iteration rmse = 0.9203008407995394\n",
      "------------------------------\n",
      "The 113-th iteration rmse = 0.9201271863218453\n",
      "------------------------------\n",
      "The 114-th iteration rmse = 0.9199539887212188\n",
      "------------------------------\n",
      "The 115-th iteration rmse = 0.9197811769307472\n",
      "------------------------------\n",
      "The 116-th iteration rmse = 0.9196086815068386\n",
      "------------------------------\n",
      "The 117-th iteration rmse = 0.9194364346122365\n",
      "------------------------------\n",
      "The 118-th iteration rmse = 0.9192643700028229\n",
      "------------------------------\n",
      "The 119-th iteration rmse = 0.9190924230180835\n",
      "------------------------------\n",
      "The 120-th iteration rmse = 0.9189205305751074\n",
      "------------------------------\n",
      "The 121-th iteration rmse = 0.9187486311659925\n",
      "------------------------------\n",
      "The 122-th iteration rmse = 0.9185766648585293\n",
      "------------------------------\n",
      "The 123-th iteration rmse = 0.9184045733000283\n",
      "------------------------------\n",
      "The 124-th iteration rmse = 0.9182322997241632\n",
      "------------------------------\n",
      "The 125-th iteration rmse = 0.9180597889606922\n",
      "------------------------------\n",
      "The 126-th iteration rmse = 0.9178869874479194\n",
      "------------------------------\n",
      "The 127-th iteration rmse = 0.9177138432477464\n",
      "------------------------------\n",
      "The 128-th iteration rmse = 0.9175403060631766\n",
      "------------------------------\n",
      "The 129-th iteration rmse = 0.917366327258103\n",
      "------------------------------\n",
      "The 130-th iteration rmse = 0.9171918598792305\n",
      "------------------------------\n",
      "The 131-th iteration rmse = 0.9170168586799579\n",
      "------------------------------\n",
      "The 132-th iteration rmse = 0.9168412801460516\n",
      "------------------------------\n",
      "The 133-th iteration rmse = 0.9166650825229183\n",
      "------------------------------\n",
      "The 134-th iteration rmse = 0.9164882258442965\n",
      "------------------------------\n",
      "The 135-th iteration rmse = 0.9163106719621666\n",
      "------------------------------\n",
      "The 136-th iteration rmse = 0.9161323845776695\n",
      "------------------------------\n",
      "The 137-th iteration rmse = 0.9159533292728274\n",
      "------------------------------\n",
      "The 138-th iteration rmse = 0.9157734735428359\n",
      "------------------------------\n",
      "The 139-th iteration rmse = 0.915592786828707\n",
      "------------------------------\n",
      "The 140-th iteration rmse = 0.9154112405500175\n",
      "------------------------------\n",
      "The 141-th iteration rmse = 0.9152288081375266\n",
      "------------------------------\n",
      "The 142-th iteration rmse = 0.9150454650654026\n",
      "------------------------------\n",
      "The 143-th iteration rmse = 0.9148611888828101\n",
      "------------------------------\n",
      "The 144-th iteration rmse = 0.9146759592445897\n",
      "------------------------------\n",
      "The 145-th iteration rmse = 0.9144897579407618\n",
      "------------------------------\n",
      "The 146-th iteration rmse = 0.9143025689245914\n",
      "------------------------------\n",
      "The 147-th iteration rmse = 0.9141143783389263\n",
      "------------------------------\n",
      "The 148-th iteration rmse = 0.9139251745405507\n",
      "------------------------------\n",
      "The 149-th iteration rmse = 0.9137349481222636\n",
      "------------------------------\n",
      "The 150-th iteration rmse = 0.9135436919324157\n",
      "------------------------------\n",
      "The 151-th iteration rmse = 0.913351401091634\n",
      "------------------------------\n",
      "The 152-th iteration rmse = 0.9131580730064567\n",
      "------------------------------\n",
      "The 153-th iteration rmse = 0.9129637073796337\n",
      "------------------------------\n",
      "The 154-th iteration rmse = 0.9127683062168204\n",
      "------------------------------\n",
      "The 155-th iteration rmse = 0.9125718738294368\n",
      "------------------------------\n",
      "The 156-th iteration rmse = 0.912374416833442\n",
      "------------------------------\n",
      "The 157-th iteration rmse = 0.9121759441438233\n",
      "------------------------------\n",
      "The 158-th iteration rmse = 0.9119764669645751\n",
      "------------------------------\n",
      "The 159-th iteration rmse = 0.9117759987739958\n",
      "------------------------------\n",
      "The 160-th iteration rmse = 0.9115745553051238\n",
      "------------------------------\n",
      "The 161-th iteration rmse = 0.9113721545211683\n",
      "------------------------------\n",
      "The 162-th iteration rmse = 0.9111688165858084\n",
      "------------------------------\n",
      "The 163-th iteration rmse = 0.9109645638282593\n",
      "------------------------------\n",
      "The 164-th iteration rmse = 0.9107594207030315\n",
      "------------------------------\n",
      "The 165-th iteration rmse = 0.9105534137443293\n",
      "------------------------------\n",
      "The 166-th iteration rmse = 0.9103465715150763\n",
      "------------------------------\n",
      "The 167-th iteration rmse = 0.9101389245505767\n",
      "------------------------------\n",
      "The 168-th iteration rmse = 0.909930505296845\n",
      "------------------------------\n",
      "The 169-th iteration rmse = 0.9097213480436929\n",
      "------------------------------\n",
      "The 170-th iteration rmse = 0.9095114888526645\n",
      "------------------------------\n",
      "The 171-th iteration rmse = 0.9093009654799619\n",
      "------------------------------\n",
      "The 172-th iteration rmse = 0.9090898172945328\n",
      "------------------------------\n",
      "The 173-th iteration rmse = 0.9088780851915197\n",
      "------------------------------\n",
      "The 174-th iteration rmse = 0.9086658115013081\n",
      "------------------------------\n",
      "The 175-th iteration rmse = 0.9084530398944275\n",
      "------------------------------\n",
      "The 176-th iteration rmse = 0.9082398152826139\n",
      "------------------------------\n",
      "The 177-th iteration rmse = 0.9080261837163455\n",
      "------------------------------\n",
      "The 178-th iteration rmse = 0.9078121922792\n",
      "------------------------------\n",
      "The 179-th iteration rmse = 0.9075978889794175\n",
      "------------------------------\n",
      "The 180-th iteration rmse = 0.9073833226390489\n",
      "------------------------------\n",
      "The 181-th iteration rmse = 0.9071685427811155\n",
      "------------------------------\n",
      "The 182-th iteration rmse = 0.9069535995152116\n",
      "------------------------------\n",
      "The 183-th iteration rmse = 0.9067385434219923\n",
      "------------------------------\n",
      "The 184-th iteration rmse = 0.9065234254370065\n",
      "------------------------------\n",
      "The 185-th iteration rmse = 0.9063082967343379\n",
      "------------------------------\n",
      "The 186-th iteration rmse = 0.9060932086105321\n",
      "------------------------------\n",
      "The 187-th iteration rmse = 0.9058782123692677\n",
      "------------------------------\n",
      "The 188-th iteration rmse = 0.9056633592072502\n",
      "------------------------------\n",
      "The 189-th iteration rmse = 0.905448700101788\n",
      "------------------------------\n",
      "The 190-th iteration rmse = 0.9052342857005022\n",
      "------------------------------\n",
      "The 191-th iteration rmse = 0.9050201662136116\n",
      "------------------------------\n",
      "The 192-th iteration rmse = 0.9048063913092215\n",
      "------------------------------\n",
      "The 193-th iteration rmse = 0.9045930100120111\n",
      "------------------------------\n",
      "The 194-th iteration rmse = 0.904380070605716\n",
      "------------------------------\n",
      "The 195-th iteration rmse = 0.904167620539757\n",
      "------------------------------\n",
      "The 196-th iteration rmse = 0.9039557063403441\n",
      "------------------------------\n",
      "The 197-th iteration rmse = 0.9037443735263663\n",
      "------------------------------\n",
      "The 198-th iteration rmse = 0.9035336665303334\n",
      "------------------------------\n",
      "The 199-th iteration rmse = 0.9033236286246022\n",
      "------------------------------\n",
      "The 200-th iteration rmse = 0.9031143018531009\n",
      "------------------------------\n",
      "The 201-th iteration rmse = 0.9029057269687146\n",
      "------------------------------\n",
      "The 202-th iteration rmse = 0.9026979433764647\n",
      "------------------------------\n",
      "The 203-th iteration rmse = 0.9024909890825781\n",
      "------------------------------\n",
      "The 204-th iteration rmse = 0.9022849006495101\n",
      "------------------------------\n",
      "The 205-th iteration rmse = 0.902079713156945\n",
      "------------------------------\n",
      "The 206-th iteration rmse = 0.9018754601687625\n",
      "------------------------------\n",
      "The 207-th iteration rmse = 0.9016721737059266\n",
      "------------------------------\n",
      "The 208-th iteration rmse = 0.9014698842252274\n",
      "------------------------------\n",
      "The 209-th iteration rmse = 0.9012686206037581\n",
      "------------------------------\n",
      "The 210-th iteration rmse = 0.9010684101289989\n",
      "------------------------------\n",
      "The 211-th iteration rmse = 0.9008692784943433\n",
      "------------------------------\n",
      "The 212-th iteration rmse = 0.900671249799876\n",
      "------------------------------\n",
      "The 213-th iteration rmse = 0.9004743465581889\n",
      "------------------------------\n",
      "The 214-th iteration rmse = 0.9002785897050145\n",
      "------------------------------\n",
      "The 215-th iteration rmse = 0.9000839986144099\n",
      "------------------------------\n",
      "The 216-th iteration rmse = 0.8998905911182471\n",
      "------------------------------\n",
      "The 217-th iteration rmse = 0.8996983835297144\n",
      "------------------------------\n",
      "The 218-th iteration rmse = 0.8995073906705512\n",
      "------------------------------\n",
      "The 219-th iteration rmse = 0.8993176259017224\n",
      "------------------------------\n",
      "The 220-th iteration rmse = 0.8991291011572241\n",
      "------------------------------\n",
      "The 221-th iteration rmse = 0.8989418269807298\n",
      "------------------------------\n",
      "The 222-th iteration rmse = 0.8987558125647613\n",
      "------------------------------\n",
      "The 223-th iteration rmse = 0.898571065792096\n",
      "------------------------------\n",
      "The 224-th iteration rmse = 0.8983875932791023\n",
      "------------------------------\n",
      "The 225-th iteration rmse = 0.8982054004207192\n",
      "------------------------------\n",
      "The 226-th iteration rmse = 0.8980244914367937\n",
      "------------------------------\n",
      "The 227-th iteration rmse = 0.8978448694195019\n",
      "------------------------------\n",
      "The 228-th iteration rmse = 0.8976665363815819\n",
      "------------------------------\n",
      "The 229-th iteration rmse = 0.8974894933051435\n",
      "------------------------------\n",
      "The 230-th iteration rmse = 0.8973137401907902\n",
      "------------------------------\n",
      "The 231-th iteration rmse = 0.8971392761068494\n",
      "------------------------------\n",
      "The 232-th iteration rmse = 0.8969660992384829\n",
      "------------------------------\n",
      "The 233-th iteration rmse = 0.8967942069364863\n",
      "------------------------------\n",
      "The 234-th iteration rmse = 0.8966235957655901\n",
      "------------------------------\n",
      "The 235-th iteration rmse = 0.8964542615521041\n",
      "------------------------------\n",
      "The 236-th iteration rmse = 0.8962861994307372\n",
      "------------------------------\n",
      "The 237-th iteration rmse = 0.8961194038904694\n",
      "------------------------------\n",
      "The 238-th iteration rmse = 0.8959538688193462\n",
      "------------------------------\n",
      "The 239-th iteration rmse = 0.8957895875480899\n",
      "------------------------------\n",
      "The 240-th iteration rmse = 0.8956265528924314\n",
      "------------------------------\n",
      "The 241-th iteration rmse = 0.8954647571940871\n",
      "------------------------------\n",
      "The 242-th iteration rmse = 0.8953041923603128\n",
      "------------------------------\n",
      "The 243-th iteration rmse = 0.8951448499019777\n",
      "------------------------------\n",
      "The 244-th iteration rmse = 0.8949867209701218\n",
      "------------------------------\n",
      "The 245-th iteration rmse = 0.8948297963909629\n",
      "------------------------------\n",
      "The 246-th iteration rmse = 0.8946740666993312\n",
      "------------------------------\n",
      "The 247-th iteration rmse = 0.8945195221705263\n",
      "------------------------------\n",
      "The 248-th iteration rmse = 0.8943661528505914\n",
      "------------------------------\n",
      "The 249-th iteration rmse = 0.8942139485850116\n",
      "------------------------------\n",
      "The 250-th iteration rmse = 0.8940628990458513\n",
      "------------------------------\n",
      "The 251-th iteration rmse = 0.8939129937573537\n",
      "------------------------------\n",
      "The 252-th iteration rmse = 0.893764222120026\n",
      "------------------------------\n",
      "The 253-th iteration rmse = 0.8936165734332435\n",
      "------------------------------\n",
      "The 254-th iteration rmse = 0.8934700369164128\n",
      "------------------------------\n",
      "The 255-th iteration rmse = 0.8933246017287266\n",
      "------------------------------\n",
      "The 256-th iteration rmse = 0.8931802569875678\n",
      "------------------------------\n",
      "The 257-th iteration rmse = 0.8930369917855946\n",
      "------------------------------\n",
      "The 258-th iteration rmse = 0.8928947952065678\n",
      "------------------------------\n",
      "The 259-th iteration rmse = 0.8927536563399617\n",
      "------------------------------\n",
      "The 260-th iteration rmse = 0.8926135642944205\n",
      "------------------------------\n",
      "The 261-th iteration rmse = 0.8924745082101037\n",
      "------------------------------\n",
      "The 262-th iteration rmse = 0.892336477269977\n",
      "------------------------------\n",
      "The 263-th iteration rmse = 0.892199460710108\n",
      "------------------------------\n",
      "The 264-th iteration rmse = 0.8920634478290074\n",
      "------------------------------\n",
      "The 265-th iteration rmse = 0.8919284279960781\n",
      "------------------------------\n",
      "The 266-th iteration rmse = 0.8917943906592203\n",
      "------------------------------\n",
      "The 267-th iteration rmse = 0.8916613253516452\n",
      "------------------------------\n",
      "The 268-th iteration rmse = 0.8915292216979382\n",
      "------------------------------\n",
      "The 269-th iteration rmse = 0.8913980694194339\n",
      "------------------------------\n",
      "The 270-th iteration rmse = 0.8912678583389348\n",
      "------------------------------\n",
      "The 271-th iteration rmse = 0.8911385783848287\n",
      "------------------------------\n",
      "The 272-th iteration rmse = 0.8910102195946409\n",
      "------------------------------\n",
      "The 273-th iteration rmse = 0.8908827721180697\n",
      "------------------------------\n",
      "The 274-th iteration rmse = 0.890756226219532\n",
      "------------------------------\n",
      "The 275-th iteration rmse = 0.8906305722802774\n",
      "------------------------------\n",
      "The 276-th iteration rmse = 0.8905058008000779\n",
      "------------------------------\n",
      "The 277-th iteration rmse = 0.8903819023985605\n",
      "------------------------------\n",
      "The 278-th iteration rmse = 0.8902588678161785\n",
      "------------------------------\n",
      "The 279-th iteration rmse = 0.8901366879148849\n",
      "------------------------------\n",
      "The 280-th iteration rmse = 0.8900153536785147\n",
      "------------------------------\n",
      "The 281-th iteration rmse = 0.8898948562129082\n",
      "------------------------------\n",
      "The 282-th iteration rmse = 0.8897751867458036\n",
      "------------------------------\n",
      "The 283-th iteration rmse = 0.8896563366265207\n",
      "------------------------------\n",
      "The 284-th iteration rmse = 0.8895382973254501\n",
      "------------------------------\n",
      "The 285-th iteration rmse = 0.8894210604333833\n",
      "------------------------------\n",
      "The 286-th iteration rmse = 0.8893046176606839\n",
      "------------------------------\n",
      "The 287-th iteration rmse = 0.8891889608363331\n",
      "------------------------------\n",
      "The 288-th iteration rmse = 0.8890740819068522\n",
      "------------------------------\n",
      "The 289-th iteration rmse = 0.8889599729351304\n",
      "------------------------------\n",
      "The 290-th iteration rmse = 0.8888466260991553\n",
      "------------------------------\n",
      "The 291-th iteration rmse = 0.8887340336906768\n",
      "------------------------------\n",
      "The 292-th iteration rmse = 0.8886221881137938\n",
      "------------------------------\n",
      "The 293-th iteration rmse = 0.8885110818834975\n",
      "------------------------------\n",
      "The 294-th iteration rmse = 0.8884007076241613\n",
      "------------------------------\n",
      "The 295-th iteration rmse = 0.8882910580679958\n",
      "------------------------------\n",
      "The 296-th iteration rmse = 0.8881821260534752\n",
      "------------------------------\n",
      "The 297-th iteration rmse = 0.8880739045237381\n",
      "------------------------------\n",
      "The 298-th iteration rmse = 0.8879663865249767\n",
      "------------------------------\n",
      "The 299-th iteration rmse = 0.8878595652048046\n",
      "------------------------------\n",
      "The 300-th iteration rmse = 0.8877534338106315\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.0004\n",
    "lamb=0.01\n",
    "w=np.array([[-0.1]*data.shape[0]])\n",
    "b=np.array([[0.2]*data.shape[1]])\n",
    "mean_w=np.array([[-0.1]*data.shape[0]])\n",
    "mean_b=np.array([[0.1]*data.shape[1]])\n",
    "max_iterations=300\n",
    "minbatch=10000\n",
    "row,column=data.nonzero()\n",
    "minbatch_root_mean_square_error_mean=minbatch_gradient_descent_runner_mean(data,w,b,mean_w,mean_b,minbatch,learning_rate,lamb,max_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z4m5gIRmzppu"
   },
   "source": [
    "# **Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "colab_type": "code",
    "id": "xJctgNY2zvId",
    "outputId": "72b89eb3-fc91-4aad-a43c-4b80a153581d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>\n",
       "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
       "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
       "            <div id=\"9ccfeedd-40f9-4227-a39d-3f7223e35417\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                \n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"9ccfeedd-40f9-4227-a39d-3f7223e35417\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '9ccfeedd-40f9-4227-a39d-3f7223e35417',\n",
       "                        [{\"mode\": \"lines+markers\", \"name\": \"Plain-Mini-batch\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300], \"y\": [1.6329030236470643, 1.549023943312436, 1.6595376726635387, 1.890747261958489, 2.2082854003047205, 2.521898379497624, 2.693303242412501, 2.5244794464540354, 2.0716830665939248, 1.5497834415816243, 1.2329619109244119, 1.091902656529898, 1.0386485778023238, 1.0159339465467436, 1.0041572255790914, 0.9963814284277419, 0.9904824630280189, 0.9855558092778827, 0.9813056582043479, 0.9775278916790339, 0.974147458877406, 0.9710822442385441, 0.9682969623515614, 0.9657460057535793, 0.9634066161101351, 0.9612495479920798, 0.9592582406458896, 0.957412498117962, 0.9556996443762164, 0.9541050683123261, 0.9526188129795565, 0.951229953096108, 0.9499305425600246, 0.9487122049139037, 0.9475685270423606, 0.9464929579272565, 0.9454802752356731, 0.9445252718380523, 0.9436236623892237, 0.9427712515030177, 0.9419644984389434, 0.9411999837663472, 0.9404747633445509, 0.9397860222552759, 0.9391312978367361, 0.9385082524708345, 0.937914814634718, 0.9373490279621045, 0.9368091406335851, 0.9362935039164645, 0.9358006288200756, 0.9353291170742739, 0.9348776969485679, 0.9344451757231331, 0.9340304622009447, 0.9336325335699516, 0.9332504493997731, 0.9328833282430393, 0.9325303561810505, 0.9321907700873489, 0.9318638626901238, 0.9315489704432133, 0.9312454763727349, 0.9309528011700335, 0.9306704046404879, 0.9303977790751237, 0.9301344498296994, 0.9298799703264637, 0.9296339221040513, 0.9293959109990636, 0.9291655668855822, 0.9289425407207261, 0.9287265041134491, 0.928517147010275, 0.9283141771815638, 0.9281173183871998, 0.9279263098350564, 0.9277409047107265, 0.9275608696412243, 0.9273859835040229, 0.9272160369150557, 0.9270508312544479, 0.9268901781889535, 0.9267338988676322, 0.9265818234832266, 0.9264337906025065, 0.9262896467676158, 0.9261492459341966, 0.9260124491116704, 0.9258791238884172, 0.9257491441087979, 0.9256223894692747, 0.9254987452293766, 0.9253781018661209, 0.9252603548158956, 0.9251454041771485, 0.9250331544801805, 0.9249235144300719, 0.9248163967014881, 0.9247117177153849, 0.9246093974561184, 0.9245093592766779, 0.9244115297356257, 0.9243158384265524, 0.9242222178326113, 0.9241306031766486, 0.9240409322913287, 0.9239531454869933, 0.9238671854355919, 0.9237829970538153, 0.9237005273992438, 0.9236197255666957, 0.9235405425951918, 0.9234629313757758, 0.923386846568063, 0.9233122445180584, 0.9232390831831963, 0.9231673220588994, 0.9230969221111565, 0.9230278457107403, 0.9229600565724838, 0.9228935196962318, 0.9228282013120754, 0.9227640688272398, 0.9227010907766214, 0.922639236774923, 0.9225784774719225, 0.9225187845092575, 0.9224601304799088, 0.9224024888891216, 0.9223458341176577, 0.9222901413863938, 0.9222353867229479, 0.922181546929559, 0.9221285995527367, 0.9220765228540717, 0.9220252957826003, 0.9219748979482387, 0.9219253095965878, 0.9218765115847193, 0.9218284853581776, 0.9217812129288813, 0.9217346768541002, 0.9216888602162612, 0.9216437466037138, 0.9215993200922455, 0.921555565227465, 0.921512467007866, 0.921470010868665, 0.92142818266627, 0.9213869686634384, 0.9213463555150142, 0.9213063302542847, 0.9212668802798639, 0.9212279933431423, 0.921189657536213, 0.9211518612803078, 0.921114593314676, 0.9210778426859209, 0.9210415987377385, 0.9210058511010785, 0.9209705896846698, 0.9209358046659282, 0.9209014864822026, 0.9208676258223639, 0.9208342136187087, 0.9208012410391753, 0.9207686994798429, 0.9207365805577233, 0.9207048761038085, 0.9206735781563857, 0.9206426789545904, 0.9206121709321985, 0.9205820467116449, 0.9205522990982566, 0.9205229210746911, 0.9204939057955814, 0.9204652465823593, 0.9204369369182743, 0.9204089704435784, 0.9203813409508851, 0.9203540423806857, 0.9203270688170242, 0.9203004144833203, 0.9202740737383319, 0.9202480410722627, 0.9202223111029934, 0.9201968785724456, 0.9201717383430672, 0.9201468853944301, 0.9201223148199509, 0.9200980218237059, 0.9200740017173663, 0.9200502499172217, 0.9200267619413063, 0.9200035334066159, 0.9199805600264178, 0.9199578376076424, 0.9199353620483618, 0.9199131293353464, 0.9198911355417004, 0.9198693768245692, 0.9198478494229221, 0.9198265496554012, 0.9198054739182387, 0.9197846186832365, 0.9197639804958091, 0.9197435559730902, 0.9197233418020878, 0.9197033347379056, 0.9196835316020082, 0.9196639292805481, 0.9196445247227337, 0.919625314939253, 0.9196062970007406, 0.9195874680362879, 0.9195688252320011, 0.9195503658296023, 0.9195320871250635, 0.919513986467289, 0.9194960612568307, 0.9194783089446423, 0.9194607270308671, 0.9194433130636644, 0.9194260646380643, 0.9194089793948561, 0.9193920550195119, 0.9193752892411343, 0.9193586798314379, 0.9193422246037554, 0.9193259214120758, 0.9193097681501055, 0.9192937627503535, 0.9192779031832481, 0.9192621874562694, 0.919246613613113, 0.9192311797328694, 0.9192158839292311, 0.9192007243497166, 0.9191856991749162, 0.919170806617761, 0.9191560449228051, 0.9191414123655326, 0.9191269072516781, 0.919112527916569, 0.9190982727244812, 0.9190841400680123, 0.919070128367474, 0.9190562360702959, 0.919042461650447, 0.9190288036078702, 0.9190152604679344, 0.9190018307808944, 0.9189885131213731, 0.9189753060878454, 0.9189622083021481, 0.9189492184089894, 0.9189363350754794, 0.9189235569906672, 0.918910882865092, 0.9188983114303455, 0.9188858414386396, 0.918873471662394, 0.9188612008938253, 0.9188490279445486, 0.9188369516451919, 0.9188249708450146, 0.9188130844115383, 0.9188012912301862, 0.9187895902039287, 0.918777980252941, 0.9187664603142649, 0.9187550293414817, 0.9187436863043903, 0.9187324301886938, 0.9187212599956943, 0.9187101747419917, 0.9186991734591939, 0.9186882551936297, 0.9186774190060688, 0.9186666639714508, 0.9186559891786179, 0.9186453937300529, 0.9186348767416266, 0.9186244373423462, 0.9186140746741153, 0.9186037878914898, 0.9185935761614519, 0.918583438663177, 0.9185733745878136, 0.918563383138263, 0.9185534635289699, 0.9185436149857101, 0.9185338367453871, 0.9185241280558352, 0.9185144881756195, 0.9185049163738497, 0.9184954119299881, 0.9184859741336712, 0.9184766022845259]}, {\"mode\": \"lines+markers\", \"name\": \"Plain-Gradient Descent\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300], \"y\": [1.638008102859314, 1.5721357439436643, 1.7127699215283552, 1.9646243944425752, 2.299471049623312, 2.594620940215116, 2.7111985559629215, 2.4493117016333765, 1.9496050048977474, 1.4570512941563194, 1.1915658978945243, 1.078811060535889, 1.0346627648374405, 1.0144577393267036, 1.0031751884686448, 0.9955220348470295, 0.9896352925548947, 0.9847582965079859, 0.9805523811772082, 0.9768396630665402, 0.9735157320218522, 0.970511529511924, 0.9677779889050709, 0.9652778304321182, 0.9629816951731557, 0.9608656032230305, 0.9589096344040948, 0.9570968790246577, 0.9554128688219409, 0.9538450474378647, 0.9523824763986651, 0.9510155295814544, 0.9497357192646728, 0.9485355036961021, 0.9474081738721215, 0.9463477251127205, 0.9453487784921927, 0.9444064916430505, 0.9435165018646671, 0.9426748623408858, 0.9418779997378163, 0.9411226675504316, 0.9404059138435483, 0.9397250464911375, 0.9390776082533794, 0.9384613504688389, 0.9378742135641677, 0.9373143068716928, 0.9367798932344357, 0.9362693733366417, 0.9357812734394287, 0.9353142330847847, 0.9348669952518387, 0.9344383966152308, 0.9340273595910747, 0.9336328845519467, 0.9332540433603759, 0.9328899730982714, 0.9325398707800044, 0.9322029882651555, 0.9318786279132059, 0.9315661384288749, 0.9312649112730109, 0.9309743772487126, 0.9306940035229216, 0.9304232908052434, 0.9301617708652996, 0.9299090041889463, 0.9296645779000501, 0.9294281038036011, 0.9291992166389412, 0.9289775724382361, 0.9287628470525378, 0.92855473476869, 0.928352947060921, 0.9281572114205965, 0.9279672702949978, 0.9277828800932056, 0.9276038102808352, 0.9274298425323283, 0.9272607699561121, 0.9270963963691068, 0.9269365356313444, 0.9267810110229165, 0.9266296546707785, 0.9264823070118889, 0.9263388162979147, 0.9261990381311557, 0.9260628350352985, 0.9259300760530229, 0.9258006363729269, 0.9256743969795841, 0.9255512443283921, 0.9254310700403761, 0.9253137706180354, 0.9251992471784477, 0.9250874052042973, 0.9249781543098475, 0.9248714080222536, 0.9247670835758282, 0.9246651017194785, 0.9245653865354075, 0.9244678652691514, 0.9243724681694264, 0.9242791283377771, 0.9241877815867751, 0.9240983663067165, 0.9240108233397949, 0.9239250958616568, 0.9238411292695095, 0.9237588710766593, 0.9236782708128026, 0.9235992799299378, 0.9235218517133295, 0.9234459411974024, 0.923371505086084, 0.9232985016774807, 0.9232268907924733, 0.9231566337071289, 0.9230876930885873, 0.9230200329343008, 0.9229536185143633, 0.922888416316798, 0.9228243939955885, 0.9227615203213323, 0.9226997651343306, 0.9226390993000121, 0.9225794946665166, 0.9225209240243645, 0.9224633610680483, 0.922406780359484, 0.9223511572931783, 0.9222964680630589, 0.9222426896308398, 0.9221897996958726, 0.9221377766663758, 0.9220865996319929, 0.922036248337591, 0.921986703158249, 0.921937945075363, 0.9218899556538204, 0.9218427170201776, 0.9217962118418058, 0.9217504233069364, 0.9217053351055781, 0.9216609314112537, 0.9216171968635195, 0.9215741165512212, 0.9215316759964658, 0.9214898611392559, 0.9214486583227744, 0.9214080542792672, 0.9213680361165145, 0.9213285913048535, 0.921289707664725, 0.9212513733547237, 0.9212135768601332, 0.9211763069819076, 0.921139552826099, 0.9211033037936972, 0.9210675495708651, 0.9210322801195588, 0.9209974856685061, 0.9209631567045349, 0.9209292839642306, 0.920895858425912, 0.9208628713019074, 0.9208303140311267, 0.9207981782719056, 0.9207664558951145, 0.9207351389775282, 0.9207042197954325, 0.9206736908184667, 0.9206435447036911, 0.9206137742898655, 0.9205843725919346, 0.9205553327957119, 0.9205266482527501, 0.9204983124753926, 0.9204703191320003, 0.9204426620423456, 0.920415335173162, 0.9203883326338557, 0.9203616486723545, 0.9203352776711093, 0.9203092141432246, 0.9202834527287186, 0.9202579881909189, 0.9202328154129668, 0.9202079293944472, 0.9201833252481273, 0.9201589981968021, 0.9201349435702418, 0.9201111568022462, 0.9200876334277867, 0.9200643690802427, 0.9200413594887336, 0.9200186004755257, 0.9199960879535299, 0.9199738179238762, 0.9199517864735627, 0.9199299897731823, 0.9199084240747181, 0.9198870857094067, 0.9198659710856708, 0.9198450766871126, 0.9198243990705706, 0.9198039348642332, 0.9197836807658145, 0.9197636335407798, 0.9197437900206273, 0.9197241471012231, 0.919704701741181, 0.9196854509602953, 0.9196663918380182, 0.9196475215119794, 0.9196288371765549, 0.9196103360814721, 0.9195920155304574, 0.9195738728799231, 0.9195559055376932, 0.9195381109617644, 0.9195204866591008, 0.919503030184467, 0.9194857391392904, 0.9194686111705571, 0.9194516439697398, 0.9194348352717541, 0.9194181828539435, 0.9194016845350934, 0.9193853381744743, 0.9193691416709064, 0.9193530929618533, 0.9193371900225404, 0.9193214308650965, 0.9193058135377163, 0.9192903361238511, 0.919274996741413, 0.9192597935420104, 0.9192447247101941, 0.9192297884627276, 0.9192149830478803, 0.9192003067447329, 0.9191857578625012, 0.9191713347398858, 0.9191570357444266, 0.9191428592718847, 0.919128803745631, 0.9191148676160604, 0.9191010493600105, 0.9190873474802028, 0.9190737605046937, 0.9190602869863422, 0.9190469255022898, 0.9190336746534508, 0.9190205330640212, 0.9190074993809927, 0.9189945722736848, 0.9189817504332863, 0.9189690325724041, 0.9189564174246314, 0.9189439037441165, 0.9189314903051503, 0.9189191759017613, 0.9189069593473151, 0.9188948394741336, 0.9188828151331129, 0.9188708851933569, 0.9188590485418183, 0.9188473040829457, 0.9188356507383436, 0.9188240874464328, 0.918812613162128, 0.9188012268565159, 0.918789927516542, 0.9187787141447091, 0.9187675857587769, 0.9187565413914713, 0.9187455800901995, 0.9187347009167735, 0.918723902947136, 0.9187131852710979, 0.9187025469920761, 0.9186919872268401, 0.9186815051052651, 0.9186710997700883, 0.9186607703766715, 0.9186505160927697, 0.918640336098304, 0.918630229585139, 0.9186201957568663, 0.9186102338285923, 0.9186003430267295, 0.9185905225887944, 0.9185807717632065, 0.918571089809096, 0.9185614759961122, 0.9185519296042367, 0.9185424499236016, 0.9185330362543099]}, {\"mode\": \"lines+markers\", \"name\": \"With Biases-Mini-batch\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300], \"y\": [1.096035349994559, 1.0736575539657933, 1.056279062270942, 1.0423965872394305, 1.0310481829717755, 1.02159476370301, 1.0135960221154101, 1.006738468750487, 1.000792482726094, 0.9955858081623129, 0.9909866178984699, 0.9868923184581162, 0.9832219177722757, 0.9799106790818102, 0.9769062886738631, 0.9741660545940425, 0.9716548247767581, 0.9693434176842036, 0.9672074245161766, 0.9652262848807143, 0.9633825663568272, 0.9616613978376359, 0.960050020065296, 0.9585374263234202, 0.9571140730985115, 0.9557716454873294, 0.9545028657678781, 0.9533013362475702, 0.9521614095164787, 0.9510780807515766, 0.9500468978709311, 0.9490638862194603, 0.9481254851483485, 0.9472284943785606, 0.946370028451763, 0.9455474778966977, 0.9447584759959446, 0.9440008702424301, 0.9432726977385546, 0.9425721639223281, 0.9418976241111136, 0.9412475674398718, 0.9406206028410721, 0.9400154467710388, 0.9394309124348121, 0.9388659003006414, 0.9383193897275779, 0.9377904315564828, 0.9372781415371815, 0.9367816944832184, 0.9363003190613977, 0.9358332931365078, 0.9353799396028012, 0.9349396226432428, 0.934511744365561, 0.9340957417709408, 0.9336910840170357, 0.9332972699419309, 0.9329138258199723, 0.932540303324015, 0.9321762776718266, 0.9318213459370829, 0.9314751255077591, 0.9311372526767618, 0.9308073813514115, 0.9304851818699482, 0.9301703399145537, 0.9298625555115881, 0.9295615421107485, 0.9292670257357737, 0.9289787442001094, 0.9286964463816472, 0.9284198915512742, 0.9281488487505039, 0.9278830962139583, 0.9276224208328813, 0.9273666176562593, 0.9271154894264556, 0.9268688461465584, 0.9266265046769341, 0.9263882883586958, 0.9261540266620132, 0.9259235548574056, 0.9256967137082993, 0.9254733491833139, 0.9252533121868655, 0.9250364583068097, 0.9248226475779555, 0.9246117442603828, 0.9244036166315989, 0.924198136791642, 0.9239951804803211, 0.9237946269058505, 0.9235963585842021, 0.9234002611885475, 0.9232062234082281, 0.9230141368167212, 0.9228238957481284, 0.922635397181742, 0.9224485406342854, 0.9222632280594554, 0.9220793637544198, 0.9218968542729549, 0.9217156083449366, 0.921535536801903, 0.9213565525084504, 0.9211785702992233, 0.9210015069212848, 0.9208252809816685, 0.9206498128999188, 0.9204750248654475, 0.9203008407995394, 0.9201271863218453, 0.9199539887212188, 0.9197811769307472, 0.9196086815068386, 0.9194364346122365, 0.9192643700028229, 0.9190924230180835, 0.9189205305751074, 0.9187486311659925, 0.9185766648585293, 0.9184045733000283, 0.9182322997241632, 0.9180597889606922, 0.9178869874479194, 0.9177138432477464, 0.9175403060631766, 0.917366327258103, 0.9171918598792305, 0.9170168586799579, 0.9168412801460516, 0.9166650825229183, 0.9164882258442965, 0.9163106719621666, 0.9161323845776695, 0.9159533292728274, 0.9157734735428359, 0.915592786828707, 0.9154112405500175, 0.9152288081375266, 0.9150454650654026, 0.9148611888828101, 0.9146759592445897, 0.9144897579407618, 0.9143025689245914, 0.9141143783389263, 0.9139251745405507, 0.9137349481222636, 0.9135436919324157, 0.913351401091634, 0.9131580730064567, 0.9129637073796337, 0.9127683062168204, 0.9125718738294368, 0.912374416833442, 0.9121759441438233, 0.9119764669645751, 0.9117759987739958, 0.9115745553051238, 0.9113721545211683, 0.9111688165858084, 0.9109645638282593, 0.9107594207030315, 0.9105534137443293, 0.9103465715150763, 0.9101389245505767, 0.909930505296845, 0.9097213480436929, 0.9095114888526645, 0.9093009654799619, 0.9090898172945328, 0.9088780851915197, 0.9086658115013081, 0.9084530398944275, 0.9082398152826139, 0.9080261837163455, 0.9078121922792, 0.9075978889794175, 0.9073833226390489, 0.9071685427811155, 0.9069535995152116, 0.9067385434219923, 0.9065234254370065, 0.9063082967343379, 0.9060932086105321, 0.9058782123692677, 0.9056633592072502, 0.905448700101788, 0.9052342857005022, 0.9050201662136116, 0.9048063913092215, 0.9045930100120111, 0.904380070605716, 0.904167620539757, 0.9039557063403441, 0.9037443735263663, 0.9035336665303334, 0.9033236286246022, 0.9031143018531009, 0.9029057269687146, 0.9026979433764647, 0.9024909890825781, 0.9022849006495101, 0.902079713156945, 0.9018754601687625, 0.9016721737059266, 0.9014698842252274, 0.9012686206037581, 0.9010684101289989, 0.9008692784943433, 0.900671249799876, 0.9004743465581889, 0.9002785897050145, 0.9000839986144099, 0.8998905911182471, 0.8996983835297144, 0.8995073906705512, 0.8993176259017224, 0.8991291011572241, 0.8989418269807298, 0.8987558125647613, 0.898571065792096, 0.8983875932791023, 0.8982054004207192, 0.8980244914367937, 0.8978448694195019, 0.8976665363815819, 0.8974894933051435, 0.8973137401907902, 0.8971392761068494, 0.8969660992384829, 0.8967942069364863, 0.8966235957655901, 0.8964542615521041, 0.8962861994307372, 0.8961194038904694, 0.8959538688193462, 0.8957895875480899, 0.8956265528924314, 0.8954647571940871, 0.8953041923603128, 0.8951448499019777, 0.8949867209701218, 0.8948297963909629, 0.8946740666993312, 0.8945195221705263, 0.8943661528505914, 0.8942139485850116, 0.8940628990458513, 0.8939129937573537, 0.893764222120026, 0.8936165734332435, 0.8934700369164128, 0.8933246017287266, 0.8931802569875678, 0.8930369917855946, 0.8928947952065678, 0.8927536563399617, 0.8926135642944205, 0.8924745082101037, 0.892336477269977, 0.892199460710108, 0.8920634478290074, 0.8919284279960781, 0.8917943906592203, 0.8916613253516452, 0.8915292216979382, 0.8913980694194339, 0.8912678583389348, 0.8911385783848287, 0.8910102195946409, 0.8908827721180697, 0.890756226219532, 0.8906305722802774, 0.8905058008000779, 0.8903819023985605, 0.8902588678161785, 0.8901366879148849, 0.8900153536785147, 0.8898948562129082, 0.8897751867458036, 0.8896563366265207, 0.8895382973254501, 0.8894210604333833, 0.8893046176606839, 0.8891889608363331, 0.8890740819068522, 0.8889599729351304, 0.8888466260991553, 0.8887340336906768, 0.8886221881137938, 0.8885110818834975, 0.8884007076241613, 0.8882910580679958, 0.8881821260534752, 0.8880739045237381, 0.8879663865249767, 0.8878595652048046, 0.8877534338106315]}, {\"mode\": \"lines+markers\", \"name\": \"With Biases-Gradient Descent\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300], \"y\": [1.0954603507443303, 1.0727784690733126, 1.0552609488382696, 1.0413367155133255, 1.0300016405054941, 1.020590955945247, 1.0126490297902806, 1.0058534345501153, 0.9999694962741976, 0.9948222401485397, 0.9902785034805677, 0.9862351627212789, 0.9826111524724035, 0.9793419106505721, 0.9763754225359026, 0.9736693472599943, 0.9711888947228884, 0.968905233606874, 0.9667942820172104, 0.9648357780795954, 0.9630125581701815, 0.9613099910068427, 0.9597155300193003, 0.9582183563747289, 0.9568090921272759, 0.9554795680745221, 0.9542226346348731, 0.9530320068098157, 0.95190213634119, 0.9508281057099932, 0.9498055397863611, 0.9488305318280477, 0.9478995812072394, 0.947009540774127, 0.9461575721778319, 0.9453411077887058, 0.9445578181214919, 0.9438055838616456, 0.9430824717591951, 0.9423867137845692, 0.941716689045799, 0.9410709080515908, 0.940447998974073, 0.9398466956216797, 0.9392658268791719, 0.9387043074101866, 0.9381611294494006, 0.9376353555377985, 0.9371261120764747, 0.9366325835927471, 0.9361540076277832, 0.9356896701678622, 0.9352389015523332, 0.9348010728005678, 0.9343755923080471, 0.9339619028683899, 0.9335594789838184, 0.9331678244314211, 0.932786470056742, 0.932414971769797, 0.9320529087217247, 0.9316998816429124, 0.931355511325761, 0.9310194372372544, 0.9306913162482011, 0.9303708214675707, 0.930057641171631, 0.9297514778187547, 0.9294520471417832, 0.9291590773107031, 0.9288723081591768, 0.928591490469162, 0.928316385308444, 0.9280467634164464, 0.9277824046341698, 0.9275230973745021, 0.9272686381295416, 0.927018831011893, 0.9267734873271957, 0.9265324251753986, 0.9262954690785529, 0.9260624496330726, 0.9258332031846376, 0.9256075715240542, 0.9253854016025543, 0.9251665452651572, 0.9249508590008224, 0.9247382037082555, 0.9245284444763139, 0.92432145037806, 0.9241170942775843, 0.923915252648803, 0.9237158054055027, 0.9235186357419541, 0.9233236299834886, 0.9231306774464813, 0.9229396703072079, 0.9227505034791268, 0.9225630744981265, 0.9223772834153606, 0.922193032697291, 0.922010227132604, 0.9218287737456862, 0.9216485817163806, 0.9214695623057433, 0.9212916287875688, 0.9211146963854451, 0.9209386822151354, 0.9207635052320822, 0.9205890861838516, 0.9204153475673497, 0.920242213590637, 0.9200696101391984, 0.9198974647465186, 0.9197257065688133, 0.919554266363799, 0.9193830764733548, 0.9192120708099583, 0.9190411848467621, 0.918870355611197, 0.9186995216819706, 0.9185286231893361, 0.9183576018185112, 0.9181864008161167, 0.9180149649995009, 0.9178432407688203, 0.9176711761217352, 0.9174987206705754, 0.9173258256618287, 0.9171524439977987, 0.9169785302602596, 0.9168040407359569, 0.916628933443758, 0.9164531681632839, 0.9162767064648197, 0.9160995117403105, 0.9159215492352306, 0.9157427860811098, 0.9155631913284976, 0.9153827359801241, 0.9152013930240234, 0.9150191374663758, 0.9148359463638078, 0.9146517988548963, 0.9144666761906116, 0.9142805617634271, 0.9140934411348305, 0.9139053020609558, 0.9137161345160626, 0.9135259307135912, 0.9133346851245175, 0.9131423944927363, 0.9129490578472139, 0.9127546765106449, 0.9125592541043686, 0.912362796549307, 0.9121653120626873, 0.9119668111503481, 0.9117673065944251, 0.9115668134362364, 0.9113653489542124, 0.9111629326367324, 0.91095958614974, 0.9107553332990781, 0.9105501999874402, 0.9103442141659458, 0.9101374057802999, 0.9099298067115855, 0.9097214507117335, 0.9095123733337631, 0.9093026118569159, 0.9090922052068325, 0.9088811938709666, 0.9086696198094416, 0.9084575263616199, 0.9082449581486446, 0.9080319609722768, 0.9078185817103654, 0.9076048682093059, 0.9073908691738808, 0.9071766340548939, 0.9069622129350131, 0.9067476564132789, 0.9065330154887298, 0.9063183414436047, 0.9061036857266002, 0.9058890998366642, 0.9056746352077809, 0.9054603430952405, 0.9052462744638392, 0.9050324798784689, 0.9048190093975333, 0.9046059124696071, 0.9043932378337415, 0.9041810334237844, 0.9039693462770723, 0.903758222447807, 0.9035477069254091, 0.9033378435581089, 0.9031286749819873, 0.9029202425556655, 0.9027125863007885, 0.9025057448484175, 0.9022997553914123, 0.9020946536428455, 0.9018904738004472, 0.9016872485170678, 0.9014850088770789, 0.9012837843786289, 0.9010836029216227, 0.9008844908012783, 0.9006864727070661, 0.9004895717268488, 0.9002938093559697, 0.9000992055110628, 0.899905778548313, 0.8997135452858966, 0.8995225210303053, 0.8993327196062639, 0.8991441533899375, 0.8989568333451191, 0.8987707690620937, 0.8985859687988642, 0.8984024395244486, 0.8982201869639307, 0.8980392156449916, 0.897859528945624, 0.8976811291427645, 0.8975040174615803, 0.8973281941251539, 0.8971536584043432, 0.8969804086675822, 0.8968084424304243, 0.8966377564046307, 0.8964683465466327, 0.8963002081052004, 0.8961333356681853, 0.8959677232081883, 0.8958033641270575, 0.8956402512991062, 0.8954783771129637, 0.8953177335119983, 0.8951583120332384, 0.8950001038447604, 0.8948430997814998, 0.8946872903794673, 0.8945326659083531, 0.8943792164025164, 0.8942269316903713, 0.8940758014221731, 0.8939258150962284, 0.8937769620835595, 0.8936292316510533, 0.8934826129831207, 0.8933370952019318, 0.8931926673862437, 0.8930493185888909, 0.8929070378529735, 0.892765814226806, 0.8926256367776702, 0.8924864946044337, 0.8923483768490879, 0.8922112727072522, 0.8920751714377118, 0.8919400623710304, 0.8918059349173008, 0.8916727785730783, 0.8915405829275536, 0.8914093376680063, 0.8912790325846005, 0.8911496575745501, 0.8910212026457158, 0.8908936579196667, 0.8907670136342477, 0.8906412601456927, 0.8905163879303242, 0.8903923875858648, 0.8902692498324037, 0.890146965513042, 0.8900255255942492, 0.889904921165959, 0.8897851434414221, 0.8896661837568584, 0.8895480335709032, 0.8894306844638973, 0.8893141281370157, 0.8891983564112695, 0.8890833612263868, 0.8889691346395923, 0.8888556688243009, 0.8887429560687293, 0.8886309887744508, 0.8885197594548871, 0.8884092607337657, 0.8882994853435285, 0.8881904261237251, 0.888082076019374, 0.8879744280793129, 0.8878674754545411, 0.8877612113965522]}],\n",
       "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Movielens-100k Matrix Factorization\"}, \"xaxis\": {\"title\": {\"text\": \"Iterations\"}}, \"yaxis\": {\"title\": {\"text\": \"RMSE\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('9ccfeedd-40f9-4227-a39d-3f7223e35417');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                \n",
       "            </script>\n",
       "        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=np.arange(1,301), y=minbatch_root_mean_square_error,\n",
    "                    mode='lines+markers',\n",
    "                    name='Plain-Mini-batch'))\n",
    "fig.add_trace(go.Scatter(x=np.arange(1,301), y=root_mean_square_error,\n",
    "                    mode='lines+markers',\n",
    "                    name='Plain-Gradient Descent'))\n",
    "fig.add_trace(go.Scatter(x=np.arange(1,301), y=minbatch_root_mean_square_error_mean,\n",
    "                    mode='lines+markers',\n",
    "                    name='With Biases-Mini-batch'))\n",
    "fig.add_trace(go.Scatter(x=np.arange(1,301), y=root_mean_square_error_mean,\n",
    "                    mode='lines+markers',\n",
    "                    name='With Biases-Gradient Descent'))\n",
    "fig.update_layout(\n",
    "    title=\"Movielens-100k Matrix Factorization\",\n",
    "    xaxis_title=\"Iterations\",\n",
    "    yaxis_title=\"RMSE\",\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "GygvA6oGy3KJ",
    "J-AufOtroacj",
    "hn2vPfmrondi",
    "QPmyuVrj17Vm",
    "uS2BXdTBLN3y",
    "Imj9JOw9mETB",
    "EJIQB-D7n8o0",
    "fwaX_Y1HoKZ1",
    "Z4m5gIRmzppu",
    "lDDdk0kMoOvb"
   ],
   "name": "fundamental_sgd",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
